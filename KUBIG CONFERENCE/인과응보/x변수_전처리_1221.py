# -*- coding: utf-8 -*-
"""x변수 전처리_1221.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MDbqZFTeJjCoNnNPNK6Puz3f34-nlf-a
"""

from google.colab import drive
drive.mount('/content/drive')

"""X변수 추출"""

import pandas as pd

# 통합된 데이터 파일 읽기 (파일 경로 수정)
input_file_path = "/content/drive/MyDrive/KUBIG_인과추론/final_with_treat.csv"  # 원본 데이터 파일 경로
output_file_path = "selected_covariates_with_QUESTID2.csv"  # 저장 파일 경로

# 데이터 로드
df = pd.read_csv(input_file_path)

# 선택할 공변량 리스트
covariates = [
    "QUESTID2", "AGE2", "IRSEX", "INCOME", "IRMARIT", "SERVICE",
    "CG30EST", "AL30EST", "IRHHSIZ2", "NOBOOKY2",
    "COCFLAG", "COCYR", "EDUCCAT2", 'JBSTATR2', 'TXEVER', 'TXYREVER'
]

# 공변량 + QUESTID2 선택
df_selected = df[covariates]

# 선택된 데이터 저장
df_selected.to_csv(output_file_path, index=False)

print(f"QUESTID2와 선택된 공변량 데이터가 {output_file_path}에 저장되었습니다.")



"""X변수 수치형 전처리"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 파일 읽기
input_file = '/content/drive/MyDrive/KUBIG_인과추론/selected_covariates_with_QUESTID2.csv'
data = pd.read_csv(input_file)

# AGE2 값 변경
# 조건에 따라 값을 변환
age2_mapping = {
    range(1, 7): 0,
    range(7, 15): 1,
    range(15, 17): 2,
    range(17, 18): 3
}

def map_age2(value):
    for key_range, new_value in age2_mapping.items():
        if value in key_range:
            return new_value
    return value  # 해당되지 않는 값은 그대로 유지

data['AGE2'] = data['AGE2'].apply(map_age2)

# IRMARIT 값 변경
# 99를 4로 변경
data['IRMARIT'] = data['IRMARIT'].replace(99, 4)

# SERVICE 값 변경
# 99를 NaN으로 변경
data['SERVICE'] = data['SERVICE'].replace(99, pd.NA)

# INCOME 값 변경
# 1,2,3,4를 각각 0,1,2,3으로 변경
data['INCOME'] = data['INCOME'] - 1

# EDUCCAT2 값 변경
# 5를 0으로 변경, 나머지는 그대로 유지
data['EDUCCAT2'] = data['EDUCCAT2'].apply(lambda x: 0 if x == 5 else x)

# TXEVER, TXYREVER 값 변경
# 1,2를 각각 0,1로 변경
data['TXEVER'] = data['TXEVER'] - 1
data['TXYREVER'] = data['TXYREVER'] - 1

# JBSTATR2 값 변경
# 99를 NaN으로 변경, 1~9를 각각 0~8로 변경
data['JBSTATR2'] = data['JBSTATR2'].replace(99, pd.NA)
data['JBSTATR2'] = data['JBSTATR2'].apply(lambda x: x - 1 if pd.notna(x) and not pd.isna(x) else x)

# IRHHSIZ2 값 변경
# 1,2,3,4,5,6을 각각 0,1,2,3,4,5로 변경
data['IRHHSIZ2'] = data['IRHHSIZ2'] - 1

# 변환된 데이터 저장
output_file = 'X_covariates_preprocessed.csv'
data.to_csv(output_file, index=False)

print(f"변환된 데이터를 '{output_file}'에 저장했습니다.")

import pandas as pd
import numpy as np
from scipy.stats import shapiro
from sklearn.preprocessing import StandardScaler, MinMaxScaler
data = pd.read_csv("/content/X_covariates_preprocessed.csv")

def check_normality_and_scale(df, columns):
    scaler_dict = {}
    for col in columns:
        # Shapiro-Wilk 검정 수행
        stat, p_value = shapiro(df[col])
        print(f"{col} 정규성 검정 p-value: {p_value:.4f}")
        # 정규성을 만족하면 StandardScaler, 아니면 MinMaxScaler
        if p_value > 0.05:  # 정규성을 따름
            print(f"{col} -> 정규분포: StandardScaler 적용")
            scaler = StandardScaler()
        else:  # 정규성을 따르지 않음
            print(f"{col} -> 비정규분포: MinMaxScaler 적용")
            scaler = MinMaxScaler()
        df[col] = scaler.fit_transform(df[[col]])
        scaler_dict[col] = scaler
    return df, scaler_dict

# 대상 변수 리스트
columns = ['IRHHSIZ2', 'NOBOOKY2', 'CG30EST', 'AL30EST', 'AGE2', 'INCOME', 'EDUCCAT2']
data, scalers = check_normality_and_scale(data, columns)
print("\n스케일링 결과:")
print(data.head())
data_filename = "X_scaled_data.csv"
data.to_csv(data_filename, index=False)
print(f"스케일링된 데이터가 {data_filename} 파일로 저장되었습니다.")

import pandas as pd
import numpy as np
from scipy.stats import shapiro
from sklearn.preprocessing import StandardScaler, MinMaxScaler

data = pd.read_csv("/content/X_covariates_preprocessed.csv")

def check_normality_and_scale(df, columns):
    scaler_dict = {}
    for col in columns:

        # Shapiro-Wilk 검정 수행
        stat, p_value = shapiro(df[col])
        print(f"{col} 정규성 검정 p-value: {p_value:.4f}")

        # 정규성을 만족하면 StandardScaler, 아니면 MinMaxScaler
        if p_value > 0.05:  # 정규성을 따름
            print(f"{col} -> 정규분포: StandardScaler 적용")
            scaler = StandardScaler()

        else:  # 정규성을 따르지 않음
            print(f"{col} -> 비정규분포: MinMaxScaler 적용")
            scaler = MinMaxScaler()
        df[col] = scaler.fit_transform(df[[col]])
        scaler_dict[col] = scaler
    return df, scaler_dict

# MinMax Scaling 적용
scaler = MinMaxScaler()
scaled_columns = ['AGE2', 'INCOME', 'IRHHSIZ2', 'EDUCCAT2', 'NOBOOKY2', 'CG30EST', 'AL30EST']
data[scaled_columns] = scaler.fit_transform(data[scaled_columns])

data, scalers = check_normality_and_scale(data, columns)
print("\n스케일링 결과:")
print(data.head())
data_filename = "X_minmax_scaled_data.csv"
data.to_csv(data_filename, index=False)
print(f"스케일링된 데이터가 {data_filename} 파일로 저장되었습니다.")

import pandas as pd

# 첫 번째 파일에서 필요한 컬럼 추출
file1_path = '/content/drive/MyDrive/KUBIG_인과추론/final_with_treat.csv'
columns_to_extract = ['AUN_SUM', 'AUUNCOST', 'AUUNNCOV', 'AUUNENUF', 'AUUN_ANY', 'AUPOPAMT', 'HEALTH', 'K6SCMON', 'PRVHLTIN', 'GRPHLTIN', 'YEAR', 'Treatment', 'Post']
file1_data = pd.read_csv(file1_path, usecols=columns_to_extract)

# 두 번째 파일 로드
file2_path = '/content/X_minmax_scaled_data.csv'
file2_data = pd.read_csv(file2_path)

# 병합 (기본적으로 인덱스 기준으로 병합)
merged_data = pd.concat([file1_data, file2_data], axis=1)

# 병합된 데이터 확인 및 저장
output_path = '/content/merged_data.csv'
merged_data.to_csv(output_path, index=False)
print(f"병합된 데이터를 다음 경로에 저장했습니다: {output_path}")