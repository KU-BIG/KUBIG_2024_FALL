{"cells":[{"cell_type":"markdown","id":"c1f347f4-3507-423e-a8bc-68a0af7e03c0","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"c1f347f4-3507-423e-a8bc-68a0af7e03c0"},"source":["# install"]},{"cell_type":"code","execution_count":null,"id":"6fef7fc0-9c93-4116-a9de-fd7c9850c698","metadata":{"id":"6fef7fc0-9c93-4116-a9de-fd7c9850c698","outputId":"7bc85bdb-98af-460f-b7c9-de2cdb9605ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -qU python-dotenv"]},{"cell_type":"code","execution_count":null,"id":"3960874c-9c13-4884-a7ca-c98e6c593a9b","metadata":{"id":"3960874c-9c13-4884-a7ca-c98e6c593a9b","outputId":"d3d6b903-fb67-45ad-ac3a-240215a53e03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -qU langchain-community"]},{"cell_type":"code","execution_count":null,"id":"3d6f3f3c-8801-4268-b638-5e96ee9e7f65","metadata":{"id":"3d6f3f3c-8801-4268-b638-5e96ee9e7f65"},"outputs":[],"source":["from bs4 import BeautifulSoup\n","from collections import Counter\n","from dotenv import load_dotenv\n","import faiss\n","import getpass\n","from IPython import get_ipython\n","import json\n","from langchain.docstore.document import Document\n","from langchain.schema import Document\n","from langchain_text_splitters import (\n","    Language,\n","    RecursiveCharacterTextSplitter,\n",")\n","from langchain.vectorstores import Chroma\n","from langchain_upstage import UpstageEmbeddings\n","import numpy as np\n","import openai\n","import os\n","import pandas as pd\n","import re\n","import uuid\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"id":"2eaa1223-4e59-4aba-aa82-136cf94c1848","metadata":{"id":"2eaa1223-4e59-4aba-aa82-136cf94c1848"},"outputs":[],"source":["# 환경 변수 이름을 정의\n","API_KEYS = {\n","    \"UPSTAGE_API_KEY\": None,\n","    \"LANGCHAIN_API_KEY\": None,\n","    \"TAVILY_API_KEY\": None\n","}\n","\n","''' 환경 변수를 로드하는 함수 정의 '''\n","def load_env():\n","    # running in Google Colab\n","    if \"google.colab\" in str(get_ipython()):\n","        from google.colab import userdata\n","        for key in API_KEYS.keys():\n","            API_KEYS[key] = os.environ.setdefault(key, userdata.get(key))\n","\n","    # running in local Jupyter Notebook\n","    else:\n","        load_dotenv()  # .env 파일을 로드\n","        for key in API_KEYS.keys():\n","            API_KEYS[key] = os.environ.get(key)\n","\n","    return tuple(API_KEYS.values())\n","\n","# 환경 변수 값을 로드하여 변수에 저장\n","UPSTAGE_API_KEY, LANGCHAIN_API_KEY, TAVILY_API_KEY = load_env()\n"]},{"cell_type":"markdown","id":"ac760857-9fcd-4e21-8605-bd70a7015085","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"ac760857-9fcd-4e21-8605-bd70a7015085"},"source":["# DB"]},{"cell_type":"code","execution_count":null,"id":"a43545a5-43f6-432a-8f4c-45bbd009cd41","metadata":{"id":"a43545a5-43f6-432a-8f4c-45bbd009cd41"},"outputs":[],"source":["# Load JSON files\n","with open(r'C:\\Users\\wnsgu\\Desktop\\upstage\\cookbook\\file\\사진\\documents.json', 'r', encoding='utf-8') as f1, \\\n","     open(r'C:\\Users\\wnsgu\\Desktop\\upstage\\cookbook\\file\\pdf\\documents.json', 'r', encoding='utf-8') as f2:\n","    docs1 = json.load(f1)\n","    docs2 = json.load(f2)\n","\n","\n","combined_docs = docs1 + docs2\n","documents = []\n","for doc in combined_docs:\n","    if 'content' in doc:\n","        documents.append({'content': doc['content'], 'metadata': doc.get('metadata', {})})\n","    else:\n","        print(f\"문서에 'content'가 없습니다: {doc}\")"]},{"cell_type":"code","execution_count":null,"id":"2d764466-6a63-41ca-a529-e51caaa0adf9","metadata":{"id":"2d764466-6a63-41ca-a529-e51caaa0adf9"},"outputs":[],"source":["youth_policies_df = pd.read_csv(r'C:\\Users\\wnsgu\\Desktop\\upstage\\youth_policies_new.csv')\n","df_sorted = pd.read_csv(r'C:\\Users\\wnsgu\\Desktop\\upstage\\cookbook\\Solar-Fullstack-LLM-101\\df_sorted.csv')"]},{"cell_type":"code","execution_count":null,"id":"049146d2-eb58-43f0-8d9c-4f83417c0f10","metadata":{"id":"049146d2-eb58-43f0-8d9c-4f83417c0f10"},"outputs":[],"source":["# 특수 문자를 제거하는 함수 정의\n","def clean_special_characters(text):\n","    # 정규식을 사용하여 특수 문자 제거 (\\x00와 ▶ 같은 불필요한 문자 포함)\n","    text = re.sub(r'[\\x00-\\x1F▶]', '', text)  # 제어 문자와 ▶ 제거\n","    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 단일 공백으로 변환\n","    return text.strip()\n","\n","# HTML 태그를 제거하고 특수 문자도 정리하는 함수\n","def clean_html(content):\n","    soup = BeautifulSoup(content, 'html.parser')\n","    text = soup.get_text()\n","    return clean_special_characters(text)  # 추가 전처리 적용\n","# 텍스트 분할 함수 수정\n","def chunking(docs):\n","    split_docs = []\n","    for doc in docs:\n","        # HTML 태그 제거 및 특수 문자 정리\n","        cleaned_content = clean_html(doc['content'])\n","\n","        # 하나의 텍스트로 통합하여 처리\n","        split_docs.append({\n","            'content': clean_special_characters(cleaned_content),  # 전체 내용을 하나로\n","            'metadata': doc.get('metadata', {})\n","        })\n","\n","    # Return split_docs as Document objects\n","    return [Document(page_content=d['content'], metadata=d['metadata']) for d in split_docs]\n","\n","split_docs = chunking(documents)"]},{"cell_type":"code","execution_count":null,"id":"259c80e5-0100-407d-8e7e-c9cb52ac8e76","metadata":{"id":"259c80e5-0100-407d-8e7e-c9cb52ac8e76"},"outputs":[],"source":["# Update document content with youth_policies information\n","for doc in split_docs:\n","    title = doc.metadata.get('title')\n","    if title in youth_policies_df['정책 ID'].values:\n","        matching_row = youth_policies_df[youth_policies_df['정책 ID'] == title].iloc[0]\n","\n","        # 기존 metadata에 정책 ID와 정책명 추가\n","        doc.metadata['정책 ID'] = matching_row['정책 ID']\n","        doc.metadata['정책명'] = matching_row['정책명']\n","    else:\n","        # If no match, use title as 정책 ID and set 정책명 to ''\n","        doc.metadata['정책 ID'] = title  # title로 정책 ID 대체\n","        doc.metadata['정책명'] = ''\n","    additional_content = matching_row.to_dict()\n","    updated_content = f\"{doc.page_content}\\n\\nAdditional Information:\\n{json.dumps(additional_content, ensure_ascii=False, indent=2)}\"\n","    doc.page_content = updated_content\n","\n","# youth_policies_df 데이터를 split_docs에 추가 (중복 방지)\n","existing_ids = {doc.metadata.get('정책 ID') for doc in split_docs}  # 기존 정책 ID 집합\n","for index, row in youth_policies_df.iterrows():\n","    if row['정책 ID'] not in existing_ids:  # 이미 추가된 ID는 제외\n","        # 정책 ID와 정책명은 metadata로 설정\n","        metadata = {\n","            '정책 ID': row['정책 ID'],  # 반드시 존재해야 하는 열\n","            '정책명': row['정책명']   # 반드시 존재해야 하는 열\n","        }\n","\n","        # 나머지 열은 content로 설정 (한글로 유지)\n","        content = {\n","            col: row[col] for col in youth_policies_df.columns if col not in ['정책 ID', '정책명']\n","        }\n","\n","        # split_docs에 추가\n","        split_docs.append(Document(page_content=json.dumps(content, ensure_ascii=False, indent=2), metadata=metadata))\n","\n","# 기존 metadata 정리 (title과 total_pages 제거)\n","for doc in split_docs:\n","    # 정책 ID와 정책명이 metadata에 있는 경우\n","    if '정책 ID' in doc.metadata and '정책명' in doc.metadata:\n","        # title과 total_pages 제거\n","        doc.metadata.pop('title', None)\n","        doc.metadata.pop('total_pages', None)\n","\n","# Convert df_sorted to Document objects\n","df_sorted_docs = []\n","for index, row in df_sorted.iterrows():\n","    df_sorted_docs.append(Document(page_content=row['text'], metadata={'title': row['title'], 'source': 'df_sorted', 'index': index}))\n"]},{"cell_type":"code","execution_count":null,"id":"d28fa555-26a4-4804-940c-617792a479ec","metadata":{"id":"d28fa555-26a4-4804-940c-617792a479ec"},"outputs":[],"source":["# 정책명에서 R+숫자 형식의 숫자 추출 함수\n","def extract_number_from_policy_name(policy_name):\n","    match = re.search(r'R(\\d+)', policy_name)\n","    return int(match.group(1)) if match else -1  # R+숫자가 없으면 -1을 반환\n","\n","# 중복된 정책명을 처리하기 위해 `split_docs`에서 정책명 기준으로 그룹화\n","policy_name_counts = Counter([doc.metadata.get('정책명') for doc in split_docs if '정책명' in doc.metadata and doc.metadata.get('정책명') != ''])\n","\n","# 중복된 정책명 추출\n","duplicates = [name for name, count in policy_name_counts.items() if count > 1]\n","\n","# 중복된 정책명에 대해 숫자가 가장 큰 것만 남기기\n","updated_split_docs = []\n","seen_policy_names = set()\n","\n","# 중복된 정책명 처리\n","for name in duplicates:\n","    # 해당 정책명에 대한 모든 항목을 가져옴\n","    duplicate_entries = [doc for doc in split_docs if doc.metadata.get('정책명') == name and doc.metadata.get('정책명') != '']\n","\n","    # 숫자 값을 기준으로 가장 큰 항목만 선택\n","    max_entry = max(duplicate_entries, key=lambda x: extract_number_from_policy_name(x.metadata.get('정책명')))\n","\n","    # 최종 리스트에 추가 (중복을 피하기 위해 이미 처리한 정책명은 추가하지 않음)\n","    if name not in seen_policy_names:\n","        updated_split_docs.append(max_entry)\n","        seen_policy_names.add(name)\n","\n","# `updated_split_docs`에는 중복을 처리한 항목들만 남음\n","# 나머지 split_docs에 대해 중복 처리되지 않은 항목은 그대로 추가\n","for doc in split_docs:\n","    if '정책명' in doc.metadata and doc.metadata['정책명'] == '':\n","        updated_split_docs.append(doc)  # 정책명이 빈 문자열인 항목은 그대로 추가\n","    elif '정책명' in doc.metadata and doc.metadata['정책명'] not in seen_policy_names:\n","        updated_split_docs.append(doc)  # 중복 처리되지 않은 정책명은 그대로 추가\n"]},{"cell_type":"code","execution_count":null,"id":"9628961b-c10e-4741-b336-0d47653e5c3b","metadata":{"id":"9628961b-c10e-4741-b336-0d47653e5c3b","outputId":"d02a0926-5eee-4dbe-b15d-781c57c5f77c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average content length before Additional Information: 6203.77\n","Max content length before Additional Information: 74247\n","Average content length after Additional Information: 1954.22\n","Max content length after Additional Information: 3880\n","Average content length without Additional Information: 1342.50\n","Max content length without Additional Information: 3978\n"]}],"source":["# Initialize lists to hold content lengths based on different conditions\n","content_with_additional_info_before = []  # Before Additional Information\n","content_with_additional_info_after = []   # After Additional Information\n","content_without_additional_info = []      # Without Additional Information\n","\n","\n","# Step 1: Iterate over split_docs and classify based on conditions\n","for doc in split_docs:\n","    original_content_length = len(doc.page_content)  # Original content length\n","\n","    # Check policy name condition\n","    if doc.metadata.get('정책명') != '':\n","        # If policy name is empty, handle as \"content_with_policy_name_empty\"\n","        if \"Additional Information\" in doc.page_content:\n","            # Split the content into before and after 'Additional Information'\n","            content_before_additional_info = doc.page_content.split('\\n\\nAdditional Information:\\n')[0]\n","            content_after_additional_info = doc.page_content.split('\\n\\nAdditional Information:\\n')[1]\n","            content_with_additional_info_before.append(len(content_before_additional_info))\n","            content_with_additional_info_after.append(len(content_after_additional_info))\n","        else:\n","            content_without_additional_info.append(original_content_length)\n","    else :\n","        content_with_additional_info_before.append(original_content_length)\n","\n","# Step 2: Analyze text size for each condition and print max and average content lengths\n","def print_content_analysis(content_list, label):\n","    if content_list:\n","        avg_content_length = sum(content_list) / len(content_list)\n","        max_content_length = max(content_list)\n","        print(f\"Average content length {label}: {avg_content_length:.2f}\")\n","        print(f\"Max content length {label}: {max_content_length}\")\n","    else:\n","        print(f\"No documents found for {label}\")\n","\n","# Print analysis for each case\n","print_content_analysis(content_with_additional_info_before, \"before Additional Information\")\n","print_content_analysis(content_with_additional_info_after, \"after Additional Information\")\n","print_content_analysis(content_without_additional_info, \"without Additional Information\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d8bcc448-64ba-4a95-9111-1884d6e9c574","metadata":{"id":"d8bcc448-64ba-4a95-9111-1884d6e9c574","outputId":"5c7ddad3-ece9-4a09-d3d4-5ca1b9f54a32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Added batch 1 of 33\n","Added batch 2 of 33\n","Added batch 3 of 33\n","Added batch 4 of 33\n","Added batch 5 of 33\n","Added batch 6 of 33\n","Added batch 7 of 33\n","Added batch 8 of 33\n","Added batch 9 of 33\n","Added batch 10 of 33\n","Added batch 11 of 33\n","Added batch 12 of 33\n","Added batch 13 of 33\n","Added batch 14 of 33\n","Added batch 15 of 33\n","Added batch 16 of 33\n","Added batch 17 of 33\n","Added batch 18 of 33\n","Added batch 19 of 33\n","Added batch 20 of 33\n","Added batch 21 of 33\n","Added batch 22 of 33\n","Added batch 23 of 33\n","Added batch 24 of 33\n","Added batch 25 of 33\n","Added batch 26 of 33\n","Added batch 27 of 33\n","Added batch 28 of 33\n","Added batch 29 of 33\n","Added batch 30 of 33\n","Added batch 31 of 33\n","Added batch 32 of 33\n","Added batch 33 of 33\n","All documents added successfully!\n"]}],"source":["from uuid import uuid4\n","\n","# Embedding 설정 및 Chroma DB 경로\n","embedding_function = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n","persist_directory = r'C:\\Users\\wnsgu\\Desktop\\upstage\\cookbook\\chroma_db\\policy_combined'\n","db = Chroma(embedding_function=embedding_function, persist_directory=persist_directory)\n","\n","# 최대 청크 크기 및 배치 크기 정의\n","MAX_CHUNK_SIZE = 2000\n","MAX_BATCH_SIZE = 100\n","OVERLAP_SIZE = 50\n","\n","# Step 1: 텍스트를 청크로 나누는 함수\n","def split_into_chunks_with_overlap(text, max_chunk_size=MAX_CHUNK_SIZE, overlap_size=OVERLAP_SIZE):\n","    chunks = []\n","    start = 0\n","    while start < len(text):\n","        end = min(start + max_chunk_size, len(text))  # 텍스트 끝 초과 방지\n","        chunk = text[start:end]\n","        chunks.append(chunk)\n","        if end == len(text):  # 텍스트 끝에 도달하면 종료\n","            break\n","        start = end - overlap_size  # 겹침 고려한 새 시작 위치\n","    return chunks\n","\n","# Step 2: 문서 처리 및 청크 분리\n","all_docs_for_embedding = []\n","\n","# 데이터를 처리하는 함수\n","def process_documents(docs):\n","    for doc in docs:\n","        original_content = doc.page_content if isinstance(doc, Document) else doc.get(\"page_content\", \"\")\n","        metadata = doc.metadata if isinstance(doc, Document) else doc.get(\"metadata\", {})\n","        metadata[\"id\"] = metadata.get(\"정책 ID\", str(uuid4()))  # 정책 ID가 없으면 UUID 생성\n","\n","        # Additional Information 처리\n","        if \"Additional Information\" in original_content:\n","            # 이후 부분을 하나의 청크로\n","            content_after = original_content.split('\\n\\nAdditional Information:\\n')[1]\n","            all_docs_for_embedding.append(Document(\n","                page_content=content_after,\n","                metadata=metadata\n","            ))\n","            # 이전 부분을 청크 단위로 분리\n","            content_before = original_content.split('\\n\\nAdditional Information:\\n')[0]\n","            chunks = split_into_chunks_with_overlap(content_before)\n","            for idx, chunk in enumerate(chunks):\n","                all_docs_for_embedding.append(Document(\n","                    page_content=chunk,\n","                    metadata=metadata,\n","                ))\n","        else:\n","            # Additional Information이 없는 경우 -> 텍스트를 청크로 나눔\n","            chunks = split_into_chunks_with_overlap(original_content)\n","            for idx, chunk in enumerate(chunks):\n","                all_docs_for_embedding.append(Document(\n","                    page_content=chunk,\n","                    metadata=metadata,\n","                ))\n","\n","# Step 3: 두 데이터셋을 통합 처리\n","process_documents(split_docs)       # 첫 번째 데이터셋 처리\n","process_documents(df_sorted_docs)   # 두 번째 데이터셋 처리\n","\n","# Step 4: 문서를 배치로 ChromaDB에 추가 및 저장\n","def add_documents_in_batches(db, documents, max_batch_size=MAX_BATCH_SIZE):\n","    \"\"\"\n","    문서를 배치 단위로 벡터 데이터베이스에 추가하고 저장합니다.\n","    \"\"\"\n","    for i in range(0, len(documents), max_batch_size):\n","        batch = documents[i:i + max_batch_size]\n","        db.add_documents(batch)  # Document 객체 리스트 전달\n","        print(f\"Added batch {i // max_batch_size + 1} of {len(documents) // max_batch_size + 1}\")\n","    db.persist()  # 현재 상태를 저장\n","\n","# Step 5: 벡터 데이터베이스에 문서 추가\n","try:\n","    add_documents_in_batches(db, all_docs_for_embedding)  # 처리된 문서 전달\n","    retriever = db.as_retriever()  # 검색 가능한 Retriever 생성\n","    print(\"All documents added successfully!\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}