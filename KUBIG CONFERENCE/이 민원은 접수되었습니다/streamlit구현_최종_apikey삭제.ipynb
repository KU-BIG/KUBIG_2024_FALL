{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"qSASe8--TMmo"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxuocTPANjQp","outputId":"7e7afef4-7d6b-4b88-ce20-72ebbb4bb31e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","API_KEYS = {\n","    \"UPSTAGE_API_KEY\": None,\n","    \"TAVILY_API_KEY\" : None\n","}\n","\n","def load_env():\n","    # 환경 변수 설정\n","    if \"google.colab\" in str(get_ipython()):  # Google Colab 환경\n","        os.environ['UPSTAGE_API_KEY'] = ''\n","        API_KEYS[\"UPSTAGE_API_KEY\"] = os.environ.get(\"UPSTAGE_API_KEY\")\n","        os.environ['TAVILY_API_KEY'] = ''\n","        API_KEYS[\"TAVILY_API_KEY\"] = os.environ.get(\"TAVILY_API_KEY\")\n","    else:  # 로컬 환경\n","        load_dotenv()  # .env 파일 로드\n","        API_KEYS[\"UPSTAGE_API_KEY\"] = os.environ.get(\"UPSTAGE_API_KEY\")\n","        API_KEYS[\"TAVILY_API_KEY\"] = os.environ.get(\"TAVILY_API_KEY\")\n","\n","    return API_KEYS[\"UPSTAGE_API_KEY\"], API_KEYS[\"TAVILY_API_KEY\"]\n","\n","UPSTAGE_API_KEY, TAVILY_API_KEY= load_env()"],"metadata":{"id":"lFsFlQevHpYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q streamlit\n","!npm install localtunnel\n","!pip install --upgrade -q accelerate bitsandbytes\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip install sentence_transformers\n","!pip install streamlit-folium\n","!npm audit fix\n","\n","!pip install -U langchain_community tiktoken langchainhub langchain langgraph chromadb\n","!pip install tavily-python\n","!pip install -qU langchain-core langchain-upstage langchain-chroma\n","!pip install -qU python-dotenv\n","!pip install -U langchain-upstage\n","!pip install -U openai\n","\n","!pip install streamlit_chat\n","!pip install qdrant_client"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTPgrgx0H-ks","outputId":"c175ca47-155a-40c1-c334-f87fe76ab589"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n","up to date, audited 23 packages in 733ms\n","\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n","\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n","\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n","\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n","2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n","\n","To address all issues (including breaking changes), run:\n","  npm audit fix --force\n","\n","Run `npm audit` for details.\n","\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0KCollecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-1i6cjn8i\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-1i6cjn8i\n","  Resolved https://github.com/huggingface/transformers.git to commit 5c75087aeee7081025370e10d1f571a11600f1ae\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2.32.3)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.0.dev0)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2024.12.14)\n","Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\n","langchain-upstage 0.4.0 requires tokenizers<0.20.0,>=0.19.1, but you have tokenizers 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.21.0\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.48.0.dev0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n","Requirement already satisfied: streamlit-folium in /usr/local/lib/python3.10/dist-packages (0.24.0)\n","Requirement already satisfied: streamlit>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from streamlit-folium) (1.41.1)\n","Requirement already satisfied: folium!=0.15.0,>=0.13 in /usr/local/lib/python3.10/dist-packages (from streamlit-folium) (0.19.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from streamlit-folium) (3.1.4)\n","Requirement already satisfied: branca in /usr/local/lib/python3.10/dist-packages (from streamlit-folium) (0.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2.32.3)\n","Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2024.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->streamlit-folium) (3.0.2)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (8.1.7)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (5.29.2)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (17.0.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (4.12.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.35.0->streamlit-folium) (6.3.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (1.18.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35.0->streamlit-folium) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium!=0.15.0,>=0.13->streamlit-folium) (2024.12.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.35.0->streamlit-folium) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.35.0->streamlit-folium) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35.0->streamlit-folium) (5.0.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (24.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.35.0->streamlit-folium) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.35.0->streamlit-folium) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.35.0->streamlit-folium) (1.17.0)\n","\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n","up to date, audited 23 packages in 875ms\n","\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n","\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K3 packages are looking for funding\n","\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K  run `npm fund` for details\n","\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n","\u001b[1m# npm audit report\u001b[22m\n","\n","\u001b[1maxios\u001b[22m  0.8.1 - 0.27.2\n","Severity: \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m\n","\u001b[1mAxios Cross-Site Request Forgery Vulnerability\u001b[22m - https://github.com/advisories/GHSA-wf5p-g6vw-rhxx\n","\u001b[33m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix --force`\n","Will install localtunnel@1.8.3, which is a breaking change\n","\u001b[2mnode_modules/axios\u001b[22m\n","  \u001b[1mlocaltunnel\u001b[22m  >=1.9.0\n","  Depends on vulnerable versions of \u001b[1maxios\u001b[22m\n","  \u001b[2mnode_modules/localtunnel\u001b[22m\n","\n","2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n","\n","To address all issues (including breaking changes), run:\n","  npm audit fix --force\n","\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0KRequirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.21)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.60)\n","Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.23)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.28)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.0)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.2)\n","Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20241016)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n","Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n","Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.48)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n","Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n","Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.6)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n","Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.4)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n","Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.50b0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n","Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb)\n","  Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n","Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n","Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n","Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n","Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n","Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n","Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n","Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n","Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n","Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.27.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.10.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","Installing collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.0\n","    Uninstalling tokenizers-0.21.0:\n","      Successfully uninstalled tokenizers-0.21.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langchain-upstage 0.4.0 requires tokenizers<0.20.0,>=0.19.1, but you have tokenizers 0.20.3 which is incompatible.\n","transformers 4.48.0.dev0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.20.3\n","Requirement already satisfied: tavily-python in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tavily-python) (2.32.3)\n","Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.8.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.28.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2024.12.14)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.2.2)\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.48.0.dev0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: langchain-upstage in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (0.3.28)\n","Requirement already satisfied: langchain-openai<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (0.2.14)\n","Requirement already satisfied: pypdf<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (4.3.1)\n","Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-upstage) (0.19.1)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (1.33)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (0.2.3)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (2.10.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (4.12.2)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.3,>=0.2->langchain-upstage) (1.58.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.3,>=0.2->langchain-upstage) (0.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2024.12.14)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.20.0,>=0.19.1->langchain-upstage) (0.27.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage) (2024.10.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage) (4.67.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-upstage) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-upstage) (2.27.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai<0.3,>=0.2->langchain-upstage) (2024.11.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.14.0)\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.58.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n","Collecting streamlit_chat\n","  Downloading streamlit_chat-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_chat) (1.41.1)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.29.2)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (17.0.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (4.12.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (6.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (1.18.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_chat) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (2024.12.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_chat) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (24.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (1.17.0)\n","Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: streamlit_chat\n","Successfully installed streamlit_chat-0.1.1\n","Collecting qdrant_client\n","  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.68.1)\n","Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n","  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.26.4)\n","Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.10.3)\n","Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.2.3)\n","Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (5.29.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (75.1.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n","Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.12.2)\n","Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n","Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.2.2)\n","Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Installing collected packages: portalocker, hyperframe, hpack, grpcio-tools, h2, qdrant_client\n","Successfully installed grpcio-tools-1.68.1 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 portalocker-2.10.1 qdrant_client-1.12.2\n"]}]},{"cell_type":"markdown","source":["# config.py"],"metadata":{"id":"Si-vwNROFtpE"}},{"cell_type":"code","source":["%%writefile config.py\n","\n","from langchain.docstore.document import Document\n","from langchain_community.retrievers import TavilySearchAPIRetriever\n","from langchain import hub\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_upstage import UpstageEmbeddings, ChatUpstage\n","from langchain.vectorstores import Chroma\n","from langgraph.graph import END, StateGraph, START\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from dotenv import load_dotenv\n","from IPython import get_ipython\n","import numpy as np\n","import os\n","import pandas as pd\n","from pprint import pprint\n","import re\n","from typing import List, Dict\n","from typing_extensions import TypedDict\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from openai import OpenAI\n","import json\n","\n","\n","client =OpenAI(api_key='')\n","\n","\n","'''\n","Embedding and Database\n","'''\n","\n","# 기존 설정\n","embedding_function = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n","\n","# 두 개의 Chroma 인스턴스 생성\n","persist_directory = '/content/drive/MyDrive/policy_chatbot/policy_combined'\n","db = Chroma(embedding_function=embedding_function, persist_directory=persist_directory)\n","retriever = db.as_retriever(search_kwargs={\"k\": 3})\n","\n","\n","'''\n","Retrieval Grader\n","'''\n","\n","# Data model\n","class GradeDocuments(BaseModel):\n","    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n","    # 검색된 문서가 질문에 적합한지를 'yes' 또는 'no'로 저장\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the conversation history and question, 'yes' or 'no'\"\n","    )\n","\n","# LLM with function call\n","llm_1 = ChatUpstage(max_tokens=200, temperature=0) # Parameter tuning 1\n","# 모델이 구조화된 데이터(GradeDocuments)를 반환하도록 설정\n","structured_llm_grader = llm_1.with_structured_output(GradeDocuments)\n","\n","# System Prompt: 검색한 문서에 유저 질문 관련 키워드가 포함되거나 의미적으로 관련이 있으면, 'relevant'로 판단. 결과는 'yes' 또는 'no'로 이진 점수를 줌.\n","system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n","    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n","    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n","    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n","    'Yes' means that the document is relevant to the question.\"\"\"\n","\n","\n","# grade_prompt = System prompt + 검색된 문서 + 사용자 질문\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n","    ]\n",")\n","# grade_prompt와 structured_llm_grader을 결합하여 문서 평가를 위한 객체 생성\n","retrieval_grader = grade_prompt | structured_llm_grader\n","\n","# Wrapper for consistent output\n","def grade_retrieval(doc_txt, user_question):\n","    \"\"\"\n","    Grades the relevance of a document to the combined question.\n","\n","    Args:\n","        doc_txt (str): The text of the document to grade.\n","        combined_question (str): The combined question including chat history.\n","\n","    Returns:\n","        str: 'yes' or 'no' based on relevance grading.\n","    \"\"\"\n","    try:\n","        # Invoke grader\n","        result = retrieval_grader.invoke({\"document\": doc_txt, \"question\": user_question})\n","        print(f\"Raw result from grader: {result}\")\n","\n","        if result and hasattr(result, \"binary_score\"):\n","            return result.binary_score\n","        else:\n","            print(f\"Invalid result structure: {result}\")\n","    except Exception as e:\n","        print(f\"Error during retrieval grading: {e}\")\n","\n","    # Default to 'no' if something goes wrong\n","    print('None')\n","    return \"no\"\n","\n","\n","'''\n","Generate\n","'''\n","\n","generate_system = \"\"\"\n","    당신은 질문에 답변을 제공하는 AI 비서입니다. 검색된 context를 바탕으로 질문에 답변하세요. 만약 답을 모를 경우, 모른다고 솔직히 말하세요. \\n\n","    청년 연령, 직업, 주거 상황, 정책 경험 여부 등 다양한 상황을 고려하여 맞춤형 답변을 제공합니다.\n","\n","    질문의 유형에 따라 아래 지침을 선택하고, 이 지침을 준수하여 답변을 작성하세요: \\n\n","    1.** 정책 추천 질문에 대한 지침 **\n","    - 아래 형식으로 답변하세요:\n","      ① 정책명:\n","      ② 추천 이유: 질문에서 제공된 연령, 상황, 선호도 등을 바탕으로 정책이 왜 적합한지 설명하세요.\n","      ③ 제공 혜택: 정책을 통해 얻을 수 있는 구체적인 이점을 서술하세요.\n","    - 정책 추천 시, 최소 2개 이상의 정책은 추천해야 하고, 아래 데이터를 적극 활용하여 가장 추천이 우선시 되는 정책부터 나열해주세요:\n","        * **복지 및 문화 관련 이슈**\n","          - 대학생: 진로 불확실성, 졸업유예 증가, 등록금 부담.\n","          - 직장인: 저임금, 고용불안(1-2년) 우려.\n","          - 미취업자: 심리상담 지원, 대중교통비 지원 선호.\n","          - 전반적으로 청년들은 안정적인 자립 지원과 금전적 지원에 대한 관심이 높음.\n","          - 대중교통비 지원, 심리상담 지원, 문화활동 및 여행 장려금 지원 등이 주요 선호 정책으로 나타남.\n","    - 높임말 대신, \"~요\"로 끝나는 말투를 사용하세요. 예: \"알려드릴게요\", \"도움이 되셨으면 해요\"\n","    - 답변의 시작은 반드시 \"세은님에게 맞는 정책을 찾아보았어요😊\\n\"로 시작하세요.\n","    - 답변의 끝은 반드시 \"\\n정책에 대해 더 구체적으로 알고 싶으신가요?\"로 끝내세요.\n","\n","    2. ** 정책 세부 정보 요청 질문에 대한 지침 **\n","    - 답변의 시작에는 반드시 사용자가 어떤 정책의 어떤 내용을 궁금해하는지 요약하고, \"제가 구체적으로 알려드릴게요😄\\n\" 문장을 추가하세요.\n","    - 높임말 대신, \"~요\"로 끝나는 말투를 사용하세요. 예: \"알려드릴게요\", \"도움이 되셨으면 해요\"\n","    - 답변은 나열식이 아닌 줄글 형식으로 작성하세요.\n","    - 답변의 끝에는 반드시 \"\\n궁금증이 해결되었나요?\" 문장을 추가하세요.\n","    - **예시 답변 형식**:\n","    > \"경기도 면접수당 정책의 신청 기간이 궁금하셨군요. 제가 구체적으로 알려드릴게요😄\\n 신청 기간은 2024년 5월 2일부터 5월 30일까지입니다. \\n궁금증이 해결되었나요?\"\n","\n","    3. ** 정책 용어 설명 요청 질문에 대한 지침 **\n","    - 답변의 시작에는 반드시 사용자가 어떤 단어의 뜻을 궁금해하는지 요약하고, \"제가 구체적으로 알려드릴게요😄\\n\" 문장을 추가하세요.\n","    - 높임말 대신, \"~요\"로 끝나는 말투를 사용하세요. 예: \"알려드릴게요\", \"도움이 되셨으면 해요\"\n","    - 문서에 있는 내용을 기반으로 답변은 나열식이 아닌 줄글 형식으로 작성하고, 간결하게 설명하세요.\n","    - 답변의 끝에는 반드시 \"\\n궁금증이 해결되었나요?\" 문장을 추가하세요.\n","    - **예시 답변 형식**:\n","    > \"가등기가 무슨 뜻인지 궁금하셨군요. 제가 구체적으로 알려드릴게요😄\\n 가등기란, 등기로 표시된 부동산의 권리관계가 외부에 표시되기 때문에 제3자에게도 대항할 수 있는데, 권리관계가 확정되지 않는 등으로 등기를 할 수 없을 경우에 임시로 하는 등기를 뜻합니다. 궁금증이 해결되었나요?\"\n","\n","    4. ** 정책 후기 요청 질문에 대한 지침 **\n","    - 답변의 시작에는 반드시 사용자가 어떤 정책의 후기를 궁금해하는지 요약하고, \"제가 검색해보았어요🔎\\n\" 문장을 추가하세요.\n","    - 높임말 대신, \"~요\"로 끝나는 말투를 사용하세요. 예: \"알려드릴게요\", \"도움이 되셨으면 해요\"\n","    - 문서에는 후기가 없으니 잘 모른다고 답변하고, 외부 검색 기능을 이용하여 답변하세요.\n","    - 답변의 끝에는 반드시 \"\\n궁금증이 해결되었나요?\" 문장을 추가하세요.\n","    - **예시 답변 형식**:\n","    > \"경기도 면접수당 정책의 실제 블로그 후기가 궁금하셨군요. 제가 검색해보았어요🔎\\n[후기 요약]\\n궁금증이 해결되었나요?\"\n","    \"\"\"\n","\n","TOKEN_PER_CHAR = 4\n","\n","def estimate_tokens(text):\n","    return len(text) // TOKEN_PER_CHAR\n","\n","# Function to format documents without exceeding the token limit\n","def format_docs(docs, max_tokens=110000):\n","    formatted_docs = []\n","    current_chunk = \"\"\n","    current_token_count = 0\n","\n","    for doc in docs:\n","        doc_content = doc.page_content\n","        doc_token_count = estimate_tokens(doc_content)\n","\n","        # If adding this document exceeds the token limit, start a new chunk\n","        if current_token_count + doc_token_count > max_tokens:\n","            formatted_docs.append(current_chunk)\n","            current_chunk = doc_content  # Start a new chunk\n","            current_token_count = doc_token_count\n","        else:\n","            current_chunk += \"\\n\\n\" + doc_content  # Append to the current chunk\n","            current_token_count += doc_token_count\n","\n","    # Add the last chunk if there's any content left\n","    if current_chunk:\n","        formatted_docs.append(current_chunk)\n","\n","    return formatted_docs\n","\n","# 모델 호출 체인\n","def rag_chain(question, context):\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=[\n","            {\"role\": \"system\",\n","             \"content\": generate_system},\n","            {\"role\": \"user\",\n","             \"content\": f\"Question: {question}\\n\\nContext: {context}\\nAnswer the question.\"},\n","        ],\n","        max_tokens=400,\n","        temperature=0,\n","    )\n","    return response.choices[0].message.content\n","\n","'''\n","Answer Grader\n","'''\n","\n","# Data model\n","class GradeAnswer(BaseModel):\n","    \"\"\"Binary score to assess answer addresses question.\"\"\"\n","\n","    binary_score: str = Field(\n","        description=\"Answer addresses the question, 'yes' or 'no'\"\n","    )\n","    confidence: float = Field(\n","        description=\"Confidence score for the assessment, range 0 to 1\"\n","    )\n","\n","# Revised System Prompt\n","answer_system_strict = \"\"\"당신은 응답이 질문에 적절한지 엄격히 평가하는 채점자입니다.\n","    1. 응답이 문서의 신뢰할 수 있는 정보를 바탕으로 질문에 명확히 답했는지 확인하세요.\n","    2. 문서 내용이 질문과 관련 없거나 응답이 문서를 정확히 반영하지 않으면 '아니오'를 반환하세요.\n","    3. 응답이 신뢰할 수 없는 내용을 포함하거나 불확실하면 '아니오'를 반환하세요.\n","    4. '예'로 평가하려면 문서 내용을 충분히 참고하여 질문을 직접 해결해야 합니다.\n","    5. 정책의 후기를 묻는 질문에 대한 답변이 '후기는 sns나 블로그를 통해 찾을 수 있어요' 와 같이 자세하지 않은 내용을 포함한 경우 '아니오'를 반환하세요.\n","\n","    응답을 반드시 다음 JSON 형식으로 반환하세요:\n","{\n","    \"binary_score\": \"yes\" 또는 \"no\",\n","    \"confidence\": 0에서 1 사이의 부동소수점 값\n","}\n","\"\"\"\n","\n","def answer_grader(question, generation, document):\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=[\n","            {\"role\": \"system\",\n","             \"content\": answer_system_strict},\n","            {\"role\": \"user\",\n","             \"content\": f\"User question: {question}\\n\\nLLM generation: {generation}\\n\\nContext: {document}\\nEvaluate the generated answer strictly based on the context.\"},\n","        ],\n","        max_tokens=400,\n","        temperature=0,\n","    )\n","    print(\"Raw response:\", response.choices[0].message.content)\n","    try:\n","        response_data = json.loads(response.choices[0].message.content)\n","        binary_score = response_data.get(\"binary_score\", \"no\")  # \"binary_score\"가 없으면 기본값 \"no\" 반환\n","    except json.JSONDecodeError as e:\n","        print(f\"Error parsing JSON: {e}\")\n","        binary_score = \"no\"  # 파싱 오류가 발생하면 기본값 \"no\" 반환\n","\n","    return binary_score\n","\n","\n","'''\n","Question Rewriter\n","'''\n","\n","# LLM\n","llm_5 = ChatUpstage(max_tokens=200, temperature=0)\n","\n","question_rewriter_system = \"\"\"\n","    당신은 입력된 질문을 벡터 저장소 검색에 최적화된 더 나은 버전으로 변환하는 질문 재작성자입니다. 입력 내용을 바탕으로, 간단하고 명료한 질문으로 재작성하세요. 문장 간 내용이 다른 범주라 느껴지면 과감히 앞 내용은 버리세요.\n","    \"\"\"\n","\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", question_rewriter_system),\n","        (\n","            \"human\",\n","           \" {question} \\n Formulate an improved question.\",\n","        ),\n","    ]\n",")\n","\n","question_rewriter = re_write_prompt | llm_5 | StrOutputParser()\n","\n","'''\n","Structure\n","'''\n","\n","class GraphState(TypedDict):\n","    \"\"\"\n","    Represents the state of our graph.\n","\n","    Attributes:\n","        question: Combined question including chat history and user query.\n","        generation: LLM generation\n","        documents: list of documents\n","    \"\"\"\n","\n","    question: str\n","    generation: str\n","    documents: List[str]\n","    first_generate_attempt: bool\n","\n","\n","'''\n","Function\n","'''\n","\n","### Nodes\n","\n","def check_documents(state):\n","    \"\"\"\n","    Check if documents exist in the current state and update the state accordingly.\n","\n","    Args:\n","        state (dict): The current graph state.\n","\n","    Returns:\n","        dict: Updated state with a flag indicating the next step.\n","    \"\"\"\n","\n","    if state.get(\"documents\"):\n","        print(\"Documents found, marking for 'generate_first'.\")\n","        state[\"next_node\"] = \"generate_first\"  # Add a marker for the next step\n","    else:\n","        print(\"No documents found, marking for 'retrieve'.\")\n","        state[\"next_node\"] = \"retrieve\"  # Add a marker for the next step\n","\n","    return state\n","\n","\n","def retrieve(state):\n","    \"\"\"\n","    Retrieve documents and update the current state.\n","\n","    Args:\n","        state (dict): The current graph state.\n","\n","    Returns:\n","        dict: Updated state with retrieved documents.\n","    \"\"\"\n","    print(\"---RETRIEVE---\")\n","    question = state[\"question\"]\n","\n","    # Process the question\n","    if re.search(r'\\n\\s*user', question):\n","        lines = question.split(\"\\nuser\")\n","        question_to_retrieve = \"\\nuser\".join(lines[:-1])\n","    else:\n","        question_to_retrieve = question\n","\n","    # Retrieve documents\n","    documents = retriever.get_relevant_documents(question_to_retrieve)\n","    print(\"Retrieved documents:\", documents)\n","\n","    # Update state\n","    state[\"documents\"] = documents\n","    return state\n","\n","\n","def generate(state):\n","    \"\"\"\n","    Generate answer based on the current state.\n","\n","    Args:\n","        state (dict): The current graph state containing question and documents.\n","\n","    Returns:\n","        dict: Updated state with the generated answer added under the key 'generation'.\n","    \"\"\"\n","    print(\"---GENERATE---\")\n","\n","    # Extract question and documents from state\n","    question = state.get(\"question\")\n","    documents = state.get(\"documents\")\n","\n","    if not question or not documents:\n","        raise ValueError(\"State must include both 'question' and 'documents' keys with valid data.\")\n","\n","    # Format the documents into a single context string\n","    context = format_docs(documents)\n","\n","    # Invoke RAG chain to get the generation\n","    generation = rag_chain(question, context)\n","\n","    # Return updated state with the generation\n","    updated_state = {\n","        **state,\n","        \"generation\": generation,\n","    }\n","\n","    return updated_state\n","\n","\n","def extract_last_question(combined_question):\n","    \"\"\"\n","    Extracts the last user question from the combined question.\n","\n","    Args:\n","        combined_question (str): The combined question including chat history.\n","\n","    Returns:\n","        str: The last user question.\n","    \"\"\"\n","    lines = combined_question.split(\"\\n\")\n","    for line in reversed(lines):\n","        if line.startswith(\"user:\"):\n","            return line[len(\"user: \"):].strip()  # Remove \"user: \" prefix\n","    return \"\"  # Default to empty if no user question found\n","\n","\n","\n","def grade_documents(state):\n","    \"\"\"\n","    Determines whether the retrieved documents are relevant to the question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with only filtered relevant documents\n","    \"\"\"\n","\n","    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Extract the last question\n","    last_question = extract_last_question(question)\n","    print(f\"Last User Question: {last_question}\")  # Debugging: Check extracted question\n","\n","    # Score each doc\n","    filtered_docs = []\n","    all_irrelevant = True\n","    for d in documents:\n","        grade = grade_retrieval(d, last_question)\n","        if grade == \"yes\":\n","            print(\"---GRADE: DOCUMENT RELEVANT---\")\n","            filtered_docs.append(d)\n","            all_irrelevant = False\n","              # At least one document is relevant\n","        else:\n","            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","            continue\n","\n","    # Update state\n","    state[\"documents\"] = filtered_docs\n","\n","    # Add a flag to indicate if all documents were irrelevant\n","    state[\"all_documents_irrelevant\"] = all_irrelevant\n","\n","    return state\n","\n","\n","def transform_query(state):\n","    \"\"\"\n","    Transform the query to produce a better question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates question key with a re-phrased question\n","    \"\"\"\n","\n","    print(\"---TRANSFORM QUERY---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Re-write question\n","    better_question = question_rewriter.invoke({\"question\": question})\n","    return {\"documents\": documents, \"question\": better_question}\n","\n","\n","### Edges\n","\n","\n","def decide_to_generate(state):\n","    \"\"\"\n","    Determines whether to generate an answer, or re-generate a question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Binary decision for next node to call\n","    \"\"\"\n","\n","    print(\"---ASSESS GRADED DOCUMENTS---\")\n","\n","    # Extract the last user question directly from the state\n","    last_question = extract_last_question(state[\"question\"])\n","    print(f\"Last User Question: {last_question}\")  # Debugging\n","\n","    # If all documents are irrelevant, transform the query\n","    if state.get(\"all_documents_irrelevant\", False):  # Check if irrelevant is True\n","        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INIT QUERY---\")\n","        return \"init_query\"\n","\n","    # If documents are relevant, generate a response\n","    else:\n","        print(\"---DECISION: GENERATE---\")\n","        return \"transform_query\"\n","\n","\n","# Initialize the not useful counter\n","not_useful_count = 0\n","first_generate_count=0\n","\n","def grade_generation_v_documents_and_question(state):\n","    \"\"\"\n","    Determines whether the generation answers the question.\n","    Returns:\n","        str: 'useful', 'not useful', or 'fallback'.\n","    \"\"\"\n","    global not_useful_count\n","    global first_generate_count\n","\n","    print(\"---GRADE GENERATION vs QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","    generation = state[\"generation\"]\n","\n","    # Extract the last question for grading\n","    last_question = extract_last_question(question)\n","\n","    try:\n","        # Perform grading based on whether it's the first attempt\n","        if first_generate_count==0 :\n","            grade = answer_grader(last_question, generation, documents)\n","        else:\n","            grade = answer_grader(question, generation, documents)\n","    except Exception as e:\n","        print(f\"Error during answer grading: {e}\")\n","        grade = \"no\"\n","    if first_generate_count== 0 :\n","        if grade == \"yes\":\n","            print(\"---FIRST GENERATE ATTEMPT: USEFUL\")\n","            return \"useful\"\n","        else:\n","            print(\"---FIRST GENERATE ATTEMPT: NOT USEFUL\")\n","            first_generate_count += 1\n","            return \"not useful\"\n","    else:\n","        if grade == \"yes\":\n","            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n","            not_useful_count = 0\n","            first_generate_count=0  # Reset the counter\n","            return \"useful\"\n","        else:\n","            print(f\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n","            not_useful_count += 1\n","            print(f\"---NOT USEFUL COUNT INCREMENTED: count={not_useful_count}---\")\n","            if not_useful_count == 1:\n","                return \"not useful\"\n","            else:\n","                return \"fallback\"\n","\n","\n","def init_query(state):\n","    \"\"\"\n","    Removes chat/document history, leaves only the last user question,\n","    and resets not_useful_count to 0.\n","    \"\"\"\n","    print(\"---INIT QUERY (CLEAR HISTORY)---\")\n","    # 마지막 사용자 질문만 뽑아오기\n","    last_question = extract_last_question(state[\"question\"])\n","\n","    # state 초기화\n","    state[\"question\"] = f\"user: {last_question}\"\n","    state[\"documents\"] = []\n","    state[\"generation\"] = \"\"\n","\n","    print(f\"[init_query] Updated question = {state['question']}\")\n","    return state\n","\n","\n","'''\n","Tavily\n","'''\n","\n","def tavily_search(state):\n","    \"\"\"\n","    External search using Tavily and process the results into a structured markdown report.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        dict: Updated state with processed documents and structured report\n","    \"\"\"\n","    print(\"---TAVILY SEARCH---\")\n","    question = state[\"question\"]\n","\n","    # Perform Tavily search\n","    tavily = TavilySearchAPIRetriever(k=3, search_depth=\"advanced\", include_domains=[\"m.blog.naver.com\"])\n","    print(\"Searching using Tavily...\")\n","\n","    docs_external = tavily.invoke(question)  # Tavily 검색 호출\n","    print(f\"Search results: {len(docs_external)} documents found.\")\n","\n","\n","    if docs_external:\n","        print(\"Relevant Tavily search results found.\")\n","        return {\"documents\": docs_external, \"question\": question}\n","    else:\n","        print(\"No relevant documents found after filtering.\")\n","        return {\"documents\": [], \"question\": question}\n","\n","'''\n","Workflow & App\n","'''\n","\n","# Define the workflow\n","workflow = StateGraph(GraphState)\n","\n","# Define the nodes\n","workflow.add_node(\"retrieve\", retrieve)  # Retrieve documents\n","workflow.add_node(\"grade_documents\", grade_documents)\n","workflow.add_node(\"retrieve_no_grade\", retrieve)  # Re-retrieve without grading\n","workflow.add_node(\"generate_first\", generate)  # First generate\n","workflow.add_node(\"generate_second\", generate)\n","workflow.add_node(\"init_query\", init_query)  # Initialize query\n","workflow.add_node(\"transform_query1\", transform_query)\n","workflow.add_node(\"transform_query2\", transform_query)  # Transform query\n","workflow.add_node(\"tavily_search\", tavily_search)  # External search node\n","workflow.add_node(\"check_documents\", check_documents)  # Custom node to check documents\n","\n","\n","# Add edges for document check\n","workflow.add_edge(START, \"check_documents\")\n","\n","workflow.add_conditional_edges(\n","    \"check_documents\",\n","    lambda state: state.get(\"next_node\"),  # Use `next_node` to determine the flow\n","    {\n","        \"generate_first\": \"generate_first\",\n","        \"retrieve\": \"retrieve\"\n","    },\n",")\n","\n","# First generate node\n","workflow.add_conditional_edges(\n","    \"generate_first\",\n","    grade_generation_v_documents_and_question,\n","    {\n","        \"useful\": \"transform_query1\",  # If generation is useful, end\n","        \"not useful\": \"retrieve\"\n","    },\n",")\n","\n","workflow.add_edge(\"transform_query1\", END)\n","\n","\n","# Define the main edges\n","workflow.add_edge(\"retrieve\", \"grade_documents\")\n","workflow.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\n","        \"init_query\": \"init_query\",\n","        \"transform_query\": \"transform_query2\"\n","    },\n",")\n","\n","workflow.add_edge(\"init_query\", \"retrieve_no_grade\")\n","workflow.add_edge(\"retrieve_no_grade\", \"transform_query2\")\n","workflow.add_edge(\"transform_query2\", \"generate_second\")\n","\n","# Second generate node\n","workflow.add_conditional_edges(\n","    \"generate_second\",\n","    grade_generation_v_documents_and_question,\n","    {\n","        \"useful\": END,  # If generation is useful, end\n","        \"not useful\": \"generate_second\",  # Retry with transformed query\n","        \"fallback\": \"tavily_search\"  # Retry generation with external search\n","    },\n",")\n","\n","workflow.add_edge(\"tavily_search\", \"generate_second\")\n","\n","# Compile the workflow\n","app = workflow.compile()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5InZHE9w7ONu","outputId":"89c3a2a0-1c3f-4f98-a041-50db5118a7cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing config.py\n"]}]},{"cell_type":"markdown","source":["# app.py"],"metadata":{"id":"pi7EViB6Fx2Q"}},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XybbycumyMmU","outputId":"659e7264-d572-4499-b8ae-65efaf6f8ba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit_chat\n","  Downloading streamlit_chat-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_chat) (1.41.1)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (5.29.2)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (17.0.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (4.12.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_chat) (6.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (1.18.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_chat) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit_chat) (2024.12.14)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit_chat) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (24.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit_chat) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit_chat) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit_chat) (1.17.0)\n","Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: streamlit_chat\n","Successfully installed streamlit_chat-0.1.1\n","Collecting qdrant_client\n","  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.68.1)\n","Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n","  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.26.4)\n","Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.10.3)\n","Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.2.3)\n","Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (5.29.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (75.1.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n","Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.12.2)\n","Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n","Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n","  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.2.2)\n","Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Installing collected packages: portalocker, hyperframe, hpack, grpcio-tools, h2, qdrant_client\n","Successfully installed grpcio-tools-1.68.1 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 portalocker-2.10.1 qdrant_client-1.12.2\n"]}]},{"cell_type":"code","source":["'''\n","%%writefile app.py\n","import streamlit as st\n","from pprint import pprint\n","import os\n","import re\n","import time\n","from pprint import pprint\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.memory import ConversationSummaryBufferMemory\n","from langchain.vectorstores import Qdrant\n","from streamlit_chat import message\n","from qdrant_client import QdrantClient\n","from openai import OpenAI\n","from config import (\n","    retriever,\n","    GradeDocuments,\n","    format_docs,\n","    rag_chain,\n","    GradeAnswer,\n","    GraphState,\n","    retrieve,\n","    generate,\n","    extract_last_question,\n","    grade_documents,\n","    transform_query,\n","    decide_to_generate,\n","    grade_generation_v_documents_and_question,\n","    init_query,\n","    tavily_search,\n","    workflow\n",")\n","\n","\n","# Initialize workflow\n","app = workflow.compile()\n","# 프레임워크 지원 시 상태 초기화\n","if hasattr(app, \"reset\"):\n","    app.reset()\n","\n","# Streamlit app configuration\n","st.set_page_config(\n","    page_title=\"Policy Chatbot\",\n","    page_icon=\":robot:\",\n",")\n","\n","# Hide Streamlit default style\n","st.markdown(\n","    \"\"\"\n","    <style>\n","    #MainMenu {visibility: hidden;}\n","    footer {visibility: hidden;}\n","    header {visibility: hidden;}\n","    </style>\n","    \"\"\",\n","    unsafe_allow_html=True\n",")\n","\n","\n","# Sidebar for chat history\n","st.sidebar.title(\"주요 기능\")\n","st.sidebar.write(\"1. 정책 추천\")\n","st.sidebar.write(\"2. 정책 세부 정보 제공\")\n","st.sidebar.write(\"3. 정책 관련 용어 설명\")\n","st.sidebar.write(\"4. 정책 후기 요약\")\n","\n","\n","# Streamlit UI\n","st.title(\"📋 청년 정책 챗봇\")\n","\n","# Initialize session state\n","if 'responses' not in st.session_state:\n","    st.session_state['responses'] = [\"청년 정책, 제가 알려드릴게요!\"]\n","if 'requests' not in st.session_state:\n","    st.session_state['requests'] = [\"\"]\n","if 'combined_question' not in st.session_state:\n","    st.session_state['combined_question'] = \"\"\n","st.session_state['not_useful_count'] = 0\n","\n","\n","# User input\n","user_question = st.text_input(\"Enter your question: \", key=\"input\", placeholder=\"Start chatting with the bot!\")\n","submit = st.button('Submit')\n","\n","if submit and user_question:\n","    if st.session_state['combined_question']:\n","        st.session_state['combined_question'] += f\"\\nuser: {user_question}\"\n","    else:\n","        st.session_state['combined_question'] = f\"user: {user_question}\"\n","\n","    inputs = {\"question\": st.session_state['combined_question']}\n","\n","    # Initialize the response to store the final generation\n","    final_response = None\n","\n","    # Execute workflow\n","    for output in app.stream(inputs):\n","        for key, value in output.items():\n","            # Capture the latest LLM generation\n","            if \"generation\" in value:\n","                final_response = value['generation']\n","\n","    # Append the final response to session state\n","    if final_response:\n","        st.session_state['responses'].append(final_response)\n","        st.session_state['requests'].append(user_question)\n","        st.session_state['combined_question'] += f\"\\nassistant: {final_response}\"\n","\n","\n","# Chat interface\n","if st.session_state['responses']:\n","    st.chat_message(\"assistant\").write(st.session_state['responses'][0])\n","    for i in range(1, len(st.session_state['responses'])):\n","        # Display user's question if it exists for the current index\n","        #if i < len(st.session_state['requests']):\n","        if not st.session_state['requests'][i]:\n","            continue\n","        st.chat_message(\"user\").write(st.session_state['requests'][i])\n","\n","        # Display assistant's response\n","        st.chat_message(\"assistant\").write(st.session_state['responses'][i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"0rXjuNd6Fy1y","outputId":"909f1a55-939c-4df8-cb3e-0e36edb41e23"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n%%writefile app.py\\n\\nimport streamlit as st\\nfrom pprint import pprint\\nimport os\\nimport re\\nimport time\\nfrom pprint import pprint\\nfrom langchain.chains import ConversationalRetrievalChain\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.memory import ConversationSummaryBufferMemory\\nfrom langchain.vectorstores import Qdrant\\nfrom streamlit_chat import message\\nfrom qdrant_client import QdrantClient\\nfrom openai import OpenAI\\nfrom config import (\\n    retriever,\\n    GradeDocuments,\\n    format_docs,\\n    rag_chain,\\n    GradeAnswer,\\n    GraphState,\\n    retrieve,\\n    generate,\\n    extract_last_question,\\n    grade_documents,\\n    transform_query,\\n    decide_to_generate,\\n    grade_generation_v_documents_and_question,\\n    init_query,\\n    tavily_search,\\n    workflow\\n)\\n\\n\\n# Initialize workflow\\napp = workflow.compile()\\n# 프레임워크 지원 시 상태 초기화\\nif hasattr(app, \"reset\"):\\n    app.reset()\\n\\n# Streamlit app configuration\\nst.set_page_config(\\n    page_title=\"Policy Chatbot\",\\n    page_icon=\":robot:\",\\n)\\n\\n# Hide Streamlit default style\\nst.markdown(\\n    \"\"\"\\n    <style>\\n    #MainMenu {visibility: hidden;}\\n    footer {visibility: hidden;}\\n    header {visibility: hidden;}\\n    </style>\\n    \"\"\",\\n    unsafe_allow_html=True\\n)\\n\\n\\n# Sidebar for chat history\\nst.sidebar.title(\"주요 기능\")\\nst.sidebar.write(\"1. 정책 추천\")\\nst.sidebar.write(\"2. 정책 세부 정보 제공\")\\nst.sidebar.write(\"3. 정책 관련 용어 설명\")\\nst.sidebar.write(\"4. 정책 후기 요약\")\\n\\n\\n# Streamlit UI\\nst.title(\"📋 청년 정책 챗봇\")\\n\\n# Initialize session state\\nif \\'responses\\' not in st.session_state:\\n    st.session_state[\\'responses\\'] = [\"청년 정책, 제가 알려드릴게요!\"]\\nif \\'requests\\' not in st.session_state:\\n    st.session_state[\\'requests\\'] = []\\nif \\'combined_question\\' not in st.session_state:\\n    st.session_state[\\'combined_question\\'] = \"\"\\nst.session_state[\\'not_useful_count\\'] = 0\\n\\n\\n# User input\\nuser_question = st.text_input(\"Enter your question: \", key=\"input\", placeholder=\"Start chatting with the bot!\")\\nsubmit = st.button(\\'Submit\\')\\n\\nif submit and user_question:\\n    if st.session_state[\\'combined_question\\']:\\n        st.session_state[\\'combined_question\\'] += f\"\\nuser: {user_question}\"\\n    else:\\n        st.session_state[\\'combined_question\\'] = f\"user: {user_question}\"\\n\\n    inputs = {\"question\": st.session_state[\\'combined_question\\']}\\n\\n    # Initialize the response to store the final generation\\n    final_response = None\\n\\n    # Execute workflow\\n    for output in app.stream(inputs):\\n        for key, value in output.items():\\n            # Capture the latest LLM generation\\n            if \"generation\" in value:\\n                final_response = value[\\'generation\\']\\n\\n    # Append the final response to session state\\n    if final_response:\\n        st.session_state[\\'responses\\'].append(final_response)\\n        st.session_state[\\'requests\\'].append(user_question)\\n        st.session_state[\\'combined_question\\'] += f\"\\nassistant: {final_response}\"\\n\\n\\n# Chat interface\\nif st.session_state[\\'responses\\']:\\n    for i in range(len(st.session_state[\\'responses\\'])):\\n        # Display user\\'s question if it exists for the current index\\n        if i < len(st.session_state[\\'requests\\']):\\n            st.chat_message(\"user\").write(st.session_state[\\'requests\\'][i])\\n\\n        # Display assistant\\'s response\\n        st.chat_message(\"assistant\").write(st.session_state[\\'responses\\'][i])\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from pprint import pprint\n","import os\n","import re\n","import time\n","from pprint import pprint\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.memory import ConversationSummaryBufferMemory\n","from langchain.vectorstores import Qdrant\n","from streamlit_chat import message\n","from qdrant_client import QdrantClient\n","from openai import OpenAI\n","from config import (\n","    retriever,\n","    GradeDocuments,\n","    format_docs,\n","    rag_chain,\n","    GradeAnswer,\n","    GraphState,\n","    retrieve,\n","    generate,\n","    extract_last_question,\n","    grade_documents,\n","    transform_query,\n","    decide_to_generate,\n","    grade_generation_v_documents_and_question,\n","    init_query,\n","    tavily_search,\n","    workflow\n",")\n","\n","\n","# Initialize workflow\n","app = workflow.compile()\n","# 프레임워크 지원 시 상태 초기화\n","if hasattr(app, \"reset\"):\n","    app.reset()\n","\n","# Streamlit app configuration\n","st.set_page_config(\n","    page_title=\"Policy Chatbot\",\n","    page_icon=\":robot:\",\n",")\n","\n","# Hide Streamlit default style\n","st.markdown(\n","    \"\"\"\n","    <style>\n","    #MainMenu {visibility: hidden;}\n","    footer {visibility: hidden;}\n","    header {visibility: hidden;}\n","    </style>\n","    \"\"\",\n","    unsafe_allow_html=True\n",")\n","\n","\n","# Sidebar for chat history\n","st.sidebar.title(\"주요 기능\")\n","st.sidebar.write(\"① 개인 맞춤형 정책 추천\")\n","st.sidebar.write(\"② 정책 세부사항 제공\")\n","st.sidebar.write(\"③ 정책 용어 의미 설명\")\n","st.sidebar.write(\"④ 실제 후기 요약\")\n","\n","\n","# Streamlit UI\n","st.title(\"✨ 청년 정책 챗봇\")\n","\n","# Initialize session state\n","if 'responses' not in st.session_state:\n","    st.session_state['responses'] = [\"청년 정책, 제가 알려드릴게요!\"]\n","if 'requests' not in st.session_state:\n","    st.session_state['requests'] = [\"\"]\n","if 'combined_question' not in st.session_state:\n","    st.session_state['combined_question'] = \"\"\n","st.session_state['not_useful_count'] = 0\n","\n","\n","# User input\n","user_question = st.chat_input(\"Enter your question: \")\n","#submit = st.button('Submit')\n","\n","if user_question:\n","    if st.session_state['combined_question']:\n","        st.session_state['combined_question'] += f\"\\nuser: {user_question}\"\n","    else:\n","        st.session_state['combined_question'] = f\"user: {user_question}\"\n","\n","    inputs = {\"question\": st.session_state['combined_question']}\n","\n","    # Initialize the response to store the final generation\n","    final_response = None\n","\n","    # Execute workflow\n","    for output in app.stream(inputs):\n","        for key, value in output.items():\n","            # Capture the latest LLM generation\n","            if \"generation\" in value:\n","                final_response = value['generation']\n","\n","    # Append the final response to session state\n","    if final_response:\n","        st.session_state['responses'].append(final_response)\n","        st.session_state['requests'].append(user_question)\n","        st.session_state['combined_question'] += f\"\\nassistant: {final_response}\"\n","\n","\n","# Chat interface\n","if st.session_state['responses']:\n","    st.chat_message(\"assistant\").write(st.session_state['responses'][0])\n","    for i in range(1, len(st.session_state['responses'])):\n","        # Display user's question if it exists for the current index\n","        #if i < len(st.session_state['requests']):\n","        if not st.session_state['requests'][i]:\n","            continue\n","        st.chat_message(\"user\").write(st.session_state['requests'][i])\n","\n","        # Display assistant's response\n","        st.chat_message(\"assistant\").write(st.session_state['responses'][i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zoy_PeBgBhBK","outputId":"efd90b1e-5669-4bc9-97a3-cd5d8ebb1fe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"markdown","source":["# run"],"metadata":{"id":"k_Gjwa_8F2Jg"}},{"cell_type":"code","source":["import urllib\n","print(\"Password/Enpoint IP for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n","\n","# \"Password/Enpoint IP for localtunnel is:\" 우측에 xx.xxx.xx.xxx 혹은 xx.xxx.xxx.xxx 형식의 숫자가 나온다.\n","\n","!streamlit run app.py &>/content/logs.txt &\n","!npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7SVSGLZF3vr","outputId":"bbc18689-7826-479a-dbf7-203625f3b886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Password/Enpoint IP for localtunnel is: 34.147.87.145\n","\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://stupid-lands-march.loca.lt\n","^C\n"]}]}]}