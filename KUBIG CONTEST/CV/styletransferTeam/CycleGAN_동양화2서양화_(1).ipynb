{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pd7urjhFPruq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b61ee81-b9fc-494d-e8c0-7c2caa4998b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Vu_uCGIEeZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tni2JsHR54N"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 원본 이미지 경로\n",
        "input_folder = '/content/drive/MyDrive/Colab Notebooks/trainB_1'  # 원본 이미지 폴더 경로\n",
        "output_folder = '/content/drive/MyDrive/Colab Notebooks/trainB'  # 전처리 후 저장될 폴더 경로\n",
        "\n",
        "# 전처리 작업 수행\n",
        "def preprocess_images(input_folder, output_folder, target_size=(256, 256)):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            with Image.open(image_path) as img:\n",
        "                # 이미지 리사이즈\n",
        "                img = img.resize(target_size, Image.BICUBIC)\n",
        "                # 전처리 후 이미지 저장\n",
        "                img.save(os.path.join(output_folder, filename))\n",
        "\n",
        "# 전처리 수행 (한국 동양화 데이터셋)\n",
        "preprocess_images('/content/drive/MyDrive/Colab Notebooks/trainB_1', '/content/drive/MyDrive/Colab Notebooks/trainB')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mSfurRXZS3vc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# ResNet 기반의 제너레이터\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=9):\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        # 입력 레이어\n",
        "        model = [nn.Conv2d(input_nc, 64, kernel_size=7, padding=3),\n",
        "                 nn.InstanceNorm2d(64),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        # 다운샘플링 레이어\n",
        "        for i in range(2):\n",
        "            mult = 2 ** i\n",
        "            model += [nn.Conv2d(64 * mult, 64 * mult * 2, kernel_size=3, stride=2, padding=1),\n",
        "                      nn.InstanceNorm2d(64 * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        # ResNet 블록\n",
        "        mult = 2 ** 2\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(64 * mult)]\n",
        "\n",
        "        # 업샘플링 레이어\n",
        "        for i in range(2):\n",
        "            mult = 2 ** (2 - i)\n",
        "            model += [nn.ConvTranspose2d(64 * mult, int(64 * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1),\n",
        "                      nn.InstanceNorm2d(int(64 * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        # 출력 레이어\n",
        "        model += [nn.Conv2d(64, output_nc, kernel_size=7, padding=3)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ResNet Block 정의\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim)\n",
        "\n",
        "    def build_conv_block(self, dim):\n",
        "        conv_block = []\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
        "                       nn.InstanceNorm2d(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
        "                       nn.InstanceNorm2d(dim)]\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YsTEdip1S9Em"
      },
      "outputs": [],
      "source": [
        "class NLayerDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc, ndf=64, n_layers=3):\n",
        "        super(NLayerDiscriminator, self).__init__()\n",
        "        kw = 4\n",
        "        padw = 1\n",
        "        sequence = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2**n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                          kernel_size=kw, stride=2, padding=padw),\n",
        "                nn.InstanceNorm2d(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2**n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
        "                      kernel_size=kw, stride=1, padding=padw),\n",
        "            nn.InstanceNorm2d(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mWE9ngqKS_4J"
      },
      "outputs": [],
      "source": [
        "# 손실 함수 정의\n",
        "criterion_GAN = nn.MSELoss()  # GAN 손실\n",
        "criterion_cycle = nn.L1Loss()  # 사이클 일관성 손실\n",
        "criterion_identity = nn.L1Loss()  # 정체성 손실\n",
        "\n",
        "# 예시로 사용할 손실 함수 래퍼\n",
        "def gan_loss(pred, target_is_real):\n",
        "    target = torch.ones_like(pred) if target_is_real else torch.zeros_like(pred)\n",
        "    return criterion_GAN(pred, target)\n",
        "\n",
        "def cycle_consistency_loss(real, rec):\n",
        "    return criterion_cycle(real, rec)\n",
        "\n",
        "def identity_loss(real, same):\n",
        "    return criterion_identity(real, same)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rumra0xiTg3O"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# CustomImageDataset 클래스 정의\n",
        "class CustomImageDataset(Dataset):  # 'Dataset'을 상속받습니다.\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# 이미지 전처리 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 데이터셋 로드\n",
        "trainA_dataset = CustomImageDataset('/content/drive/MyDrive/Colab Notebooks/trainB', transform=transform)\n",
        "trainB_dataset = CustomImageDataset('/content/drive/MyDrive/Colab Notebooks/trainA', transform=transform)\n",
        "\n",
        "# DataLoader 생성\n",
        "loader_A = DataLoader(trainA_dataset, batch_size=1, shuffle=True)\n",
        "loader_B = DataLoader(trainB_dataset, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jXKgiGwITCgf",
        "outputId": "14d959ea-934c-4897-a447-1096509acdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/300] Batch 0/39\n",
            "Epoch [1/300] Batch 0/39\n",
            "Epoch [2/300] Batch 0/39\n",
            "Epoch [3/300] Batch 0/39\n",
            "Epoch [4/300] Batch 0/39\n",
            "Epoch [5/300] Batch 0/39\n",
            "Epoch [6/300] Batch 0/39\n",
            "Epoch [7/300] Batch 0/39\n",
            "Epoch [8/300] Batch 0/39\n",
            "Epoch [9/300] Batch 0/39\n",
            "Epoch [10/300] Batch 0/39\n",
            "Epoch [11/300] Batch 0/39\n",
            "Epoch [12/300] Batch 0/39\n",
            "Epoch [13/300] Batch 0/39\n",
            "Epoch [14/300] Batch 0/39\n",
            "Epoch [15/300] Batch 0/39\n",
            "Epoch [16/300] Batch 0/39\n",
            "Epoch [17/300] Batch 0/39\n",
            "Epoch [18/300] Batch 0/39\n",
            "Epoch [19/300] Batch 0/39\n",
            "Epoch [20/300] Batch 0/39\n",
            "Epoch [21/300] Batch 0/39\n",
            "Epoch [22/300] Batch 0/39\n",
            "Epoch [23/300] Batch 0/39\n",
            "Epoch [24/300] Batch 0/39\n",
            "Epoch [25/300] Batch 0/39\n",
            "Epoch [26/300] Batch 0/39\n",
            "Epoch [27/300] Batch 0/39\n",
            "Epoch [28/300] Batch 0/39\n",
            "Epoch [29/300] Batch 0/39\n",
            "Epoch [30/300] Batch 0/39\n",
            "Epoch [31/300] Batch 0/39\n",
            "Epoch [32/300] Batch 0/39\n",
            "Epoch [33/300] Batch 0/39\n",
            "Epoch [34/300] Batch 0/39\n",
            "Epoch [35/300] Batch 0/39\n",
            "Epoch [36/300] Batch 0/39\n",
            "Epoch [37/300] Batch 0/39\n",
            "Epoch [38/300] Batch 0/39\n",
            "Epoch [39/300] Batch 0/39\n",
            "Epoch [40/300] Batch 0/39\n",
            "Epoch [41/300] Batch 0/39\n",
            "Epoch [42/300] Batch 0/39\n",
            "Epoch [43/300] Batch 0/39\n",
            "Epoch [44/300] Batch 0/39\n",
            "Epoch [45/300] Batch 0/39\n",
            "Epoch [46/300] Batch 0/39\n",
            "Epoch [47/300] Batch 0/39\n",
            "Epoch [48/300] Batch 0/39\n",
            "Epoch [49/300] Batch 0/39\n",
            "Epoch [50/300] Batch 0/39\n",
            "Epoch [51/300] Batch 0/39\n",
            "Epoch [52/300] Batch 0/39\n",
            "Epoch [53/300] Batch 0/39\n",
            "Epoch [54/300] Batch 0/39\n",
            "Epoch [55/300] Batch 0/39\n",
            "Epoch [56/300] Batch 0/39\n",
            "Epoch [57/300] Batch 0/39\n",
            "Epoch [58/300] Batch 0/39\n",
            "Epoch [59/300] Batch 0/39\n",
            "Epoch [60/300] Batch 0/39\n",
            "Epoch [61/300] Batch 0/39\n",
            "Epoch [62/300] Batch 0/39\n",
            "Epoch [63/300] Batch 0/39\n",
            "Epoch [64/300] Batch 0/39\n",
            "Epoch [65/300] Batch 0/39\n",
            "Epoch [66/300] Batch 0/39\n",
            "Epoch [67/300] Batch 0/39\n",
            "Epoch [68/300] Batch 0/39\n",
            "Epoch [69/300] Batch 0/39\n",
            "Epoch [70/300] Batch 0/39\n",
            "Epoch [71/300] Batch 0/39\n",
            "Epoch [72/300] Batch 0/39\n",
            "Epoch [73/300] Batch 0/39\n",
            "Epoch [74/300] Batch 0/39\n",
            "Epoch [75/300] Batch 0/39\n",
            "Epoch [76/300] Batch 0/39\n",
            "Epoch [77/300] Batch 0/39\n",
            "Epoch [78/300] Batch 0/39\n",
            "Epoch [79/300] Batch 0/39\n",
            "Epoch [80/300] Batch 0/39\n",
            "Epoch [81/300] Batch 0/39\n",
            "Epoch [82/300] Batch 0/39\n",
            "Epoch [83/300] Batch 0/39\n",
            "Epoch [84/300] Batch 0/39\n",
            "Epoch [85/300] Batch 0/39\n",
            "Epoch [86/300] Batch 0/39\n",
            "Epoch [87/300] Batch 0/39\n",
            "Epoch [88/300] Batch 0/39\n",
            "Epoch [89/300] Batch 0/39\n",
            "Epoch [90/300] Batch 0/39\n",
            "Epoch [91/300] Batch 0/39\n",
            "Epoch [92/300] Batch 0/39\n",
            "Epoch [93/300] Batch 0/39\n",
            "Epoch [94/300] Batch 0/39\n",
            "Epoch [95/300] Batch 0/39\n",
            "Epoch [96/300] Batch 0/39\n",
            "Epoch [97/300] Batch 0/39\n",
            "Epoch [98/300] Batch 0/39\n",
            "Epoch [99/300] Batch 0/39\n",
            "Epoch [100/300] Batch 0/39\n",
            "Epoch [101/300] Batch 0/39\n",
            "Epoch [102/300] Batch 0/39\n",
            "Epoch [103/300] Batch 0/39\n",
            "Epoch [104/300] Batch 0/39\n",
            "Epoch [105/300] Batch 0/39\n",
            "Epoch [106/300] Batch 0/39\n",
            "Epoch [107/300] Batch 0/39\n",
            "Epoch [108/300] Batch 0/39\n",
            "Epoch [109/300] Batch 0/39\n",
            "Epoch [110/300] Batch 0/39\n",
            "Epoch [111/300] Batch 0/39\n",
            "Epoch [112/300] Batch 0/39\n",
            "Epoch [113/300] Batch 0/39\n",
            "Epoch [114/300] Batch 0/39\n",
            "Epoch [115/300] Batch 0/39\n",
            "Epoch [116/300] Batch 0/39\n",
            "Epoch [117/300] Batch 0/39\n",
            "Epoch [118/300] Batch 0/39\n",
            "Epoch [119/300] Batch 0/39\n",
            "Epoch [120/300] Batch 0/39\n",
            "Epoch [121/300] Batch 0/39\n",
            "Epoch [122/300] Batch 0/39\n",
            "Epoch [123/300] Batch 0/39\n",
            "Epoch [124/300] Batch 0/39\n",
            "Epoch [125/300] Batch 0/39\n",
            "Epoch [126/300] Batch 0/39\n",
            "Epoch [127/300] Batch 0/39\n",
            "Epoch [128/300] Batch 0/39\n",
            "Epoch [129/300] Batch 0/39\n",
            "Epoch [130/300] Batch 0/39\n",
            "Epoch [131/300] Batch 0/39\n",
            "Epoch [132/300] Batch 0/39\n",
            "Epoch [133/300] Batch 0/39\n",
            "Epoch [134/300] Batch 0/39\n",
            "Epoch [135/300] Batch 0/39\n",
            "Epoch [136/300] Batch 0/39\n",
            "Epoch [137/300] Batch 0/39\n",
            "Epoch [138/300] Batch 0/39\n",
            "Epoch [139/300] Batch 0/39\n",
            "Epoch [140/300] Batch 0/39\n",
            "Epoch [141/300] Batch 0/39\n",
            "Epoch [142/300] Batch 0/39\n",
            "Epoch [143/300] Batch 0/39\n",
            "Epoch [144/300] Batch 0/39\n",
            "Epoch [145/300] Batch 0/39\n",
            "Epoch [146/300] Batch 0/39\n",
            "Epoch [147/300] Batch 0/39\n",
            "Epoch [148/300] Batch 0/39\n",
            "Epoch [149/300] Batch 0/39\n",
            "Epoch [150/300] Batch 0/39\n",
            "Epoch [151/300] Batch 0/39\n",
            "Epoch [152/300] Batch 0/39\n",
            "Epoch [153/300] Batch 0/39\n",
            "Epoch [154/300] Batch 0/39\n",
            "Epoch [155/300] Batch 0/39\n",
            "Epoch [156/300] Batch 0/39\n",
            "Epoch [157/300] Batch 0/39\n",
            "Epoch [158/300] Batch 0/39\n",
            "Epoch [159/300] Batch 0/39\n",
            "Epoch [160/300] Batch 0/39\n",
            "Epoch [161/300] Batch 0/39\n",
            "Epoch [162/300] Batch 0/39\n",
            "Epoch [163/300] Batch 0/39\n",
            "Epoch [164/300] Batch 0/39\n",
            "Epoch [165/300] Batch 0/39\n",
            "Epoch [166/300] Batch 0/39\n",
            "Epoch [167/300] Batch 0/39\n",
            "Epoch [168/300] Batch 0/39\n",
            "Epoch [169/300] Batch 0/39\n",
            "Epoch [170/300] Batch 0/39\n",
            "Epoch [171/300] Batch 0/39\n",
            "Epoch [172/300] Batch 0/39\n",
            "Epoch [173/300] Batch 0/39\n",
            "Epoch [174/300] Batch 0/39\n",
            "Epoch [175/300] Batch 0/39\n",
            "Epoch [176/300] Batch 0/39\n",
            "Epoch [177/300] Batch 0/39\n",
            "Epoch [178/300] Batch 0/39\n",
            "Epoch [179/300] Batch 0/39\n",
            "Epoch [180/300] Batch 0/39\n",
            "Epoch [181/300] Batch 0/39\n",
            "Epoch [182/300] Batch 0/39\n",
            "Epoch [183/300] Batch 0/39\n",
            "Epoch [184/300] Batch 0/39\n",
            "Epoch [185/300] Batch 0/39\n",
            "Epoch [186/300] Batch 0/39\n",
            "Epoch [187/300] Batch 0/39\n",
            "Epoch [188/300] Batch 0/39\n",
            "Epoch [189/300] Batch 0/39\n",
            "Epoch [190/300] Batch 0/39\n",
            "Epoch [191/300] Batch 0/39\n",
            "Epoch [192/300] Batch 0/39\n",
            "Epoch [193/300] Batch 0/39\n",
            "Epoch [194/300] Batch 0/39\n",
            "Epoch [195/300] Batch 0/39\n",
            "Epoch [196/300] Batch 0/39\n",
            "Epoch [197/300] Batch 0/39\n",
            "Epoch [198/300] Batch 0/39\n",
            "Epoch [199/300] Batch 0/39\n",
            "Epoch [200/300] Batch 0/39\n",
            "Epoch [201/300] Batch 0/39\n",
            "Epoch [202/300] Batch 0/39\n",
            "Epoch [203/300] Batch 0/39\n",
            "Epoch [204/300] Batch 0/39\n",
            "Epoch [205/300] Batch 0/39\n",
            "Epoch [206/300] Batch 0/39\n",
            "Epoch [207/300] Batch 0/39\n",
            "Epoch [208/300] Batch 0/39\n",
            "Epoch [209/300] Batch 0/39\n",
            "Epoch [210/300] Batch 0/39\n",
            "Epoch [211/300] Batch 0/39\n",
            "Epoch [212/300] Batch 0/39\n",
            "Epoch [213/300] Batch 0/39\n",
            "Epoch [214/300] Batch 0/39\n",
            "Epoch [215/300] Batch 0/39\n",
            "Epoch [216/300] Batch 0/39\n",
            "Epoch [217/300] Batch 0/39\n",
            "Epoch [218/300] Batch 0/39\n",
            "Epoch [219/300] Batch 0/39\n",
            "Epoch [220/300] Batch 0/39\n",
            "Epoch [221/300] Batch 0/39\n",
            "Epoch [222/300] Batch 0/39\n",
            "Epoch [223/300] Batch 0/39\n",
            "Epoch [224/300] Batch 0/39\n",
            "Epoch [225/300] Batch 0/39\n",
            "Epoch [226/300] Batch 0/39\n",
            "Epoch [227/300] Batch 0/39\n",
            "Epoch [228/300] Batch 0/39\n",
            "Epoch [229/300] Batch 0/39\n",
            "Epoch [230/300] Batch 0/39\n",
            "Epoch [231/300] Batch 0/39\n",
            "Epoch [232/300] Batch 0/39\n",
            "Epoch [233/300] Batch 0/39\n",
            "Epoch [234/300] Batch 0/39\n",
            "Epoch [235/300] Batch 0/39\n",
            "Epoch [236/300] Batch 0/39\n",
            "Epoch [237/300] Batch 0/39\n",
            "Epoch [238/300] Batch 0/39\n",
            "Epoch [239/300] Batch 0/39\n",
            "Epoch [240/300] Batch 0/39\n",
            "Epoch [241/300] Batch 0/39\n",
            "Epoch [242/300] Batch 0/39\n",
            "Epoch [243/300] Batch 0/39\n",
            "Epoch [244/300] Batch 0/39\n",
            "Epoch [245/300] Batch 0/39\n",
            "Epoch [246/300] Batch 0/39\n",
            "Epoch [247/300] Batch 0/39\n",
            "Epoch [248/300] Batch 0/39\n",
            "Epoch [249/300] Batch 0/39\n",
            "Epoch [250/300] Batch 0/39\n",
            "Epoch [251/300] Batch 0/39\n",
            "Epoch [252/300] Batch 0/39\n",
            "Epoch [253/300] Batch 0/39\n",
            "Epoch [254/300] Batch 0/39\n",
            "Epoch [255/300] Batch 0/39\n",
            "Epoch [256/300] Batch 0/39\n",
            "Epoch [257/300] Batch 0/39\n",
            "Epoch [258/300] Batch 0/39\n",
            "Epoch [259/300] Batch 0/39\n",
            "Epoch [260/300] Batch 0/39\n",
            "Epoch [261/300] Batch 0/39\n",
            "Epoch [262/300] Batch 0/39\n",
            "Epoch [263/300] Batch 0/39\n",
            "Epoch [264/300] Batch 0/39\n",
            "Epoch [265/300] Batch 0/39\n",
            "Epoch [266/300] Batch 0/39\n",
            "Epoch [267/300] Batch 0/39\n",
            "Epoch [268/300] Batch 0/39\n",
            "Epoch [269/300] Batch 0/39\n",
            "Epoch [270/300] Batch 0/39\n",
            "Epoch [271/300] Batch 0/39\n",
            "Epoch [272/300] Batch 0/39\n",
            "Epoch [273/300] Batch 0/39\n",
            "Epoch [274/300] Batch 0/39\n",
            "Epoch [275/300] Batch 0/39\n",
            "Epoch [276/300] Batch 0/39\n",
            "Epoch [277/300] Batch 0/39\n",
            "Epoch [278/300] Batch 0/39\n",
            "Epoch [279/300] Batch 0/39\n",
            "Epoch [280/300] Batch 0/39\n",
            "Epoch [281/300] Batch 0/39\n",
            "Epoch [282/300] Batch 0/39\n",
            "Epoch [283/300] Batch 0/39\n",
            "Epoch [284/300] Batch 0/39\n",
            "Epoch [285/300] Batch 0/39\n",
            "Epoch [286/300] Batch 0/39\n",
            "Epoch [287/300] Batch 0/39\n",
            "Epoch [288/300] Batch 0/39\n",
            "Epoch [289/300] Batch 0/39\n",
            "Epoch [290/300] Batch 0/39\n",
            "Epoch [291/300] Batch 0/39\n",
            "Epoch [292/300] Batch 0/39\n",
            "Epoch [293/300] Batch 0/39\n",
            "Epoch [294/300] Batch 0/39\n",
            "Epoch [295/300] Batch 0/39\n",
            "Epoch [296/300] Batch 0/39\n",
            "Epoch [297/300] Batch 0/39\n",
            "Epoch [298/300] Batch 0/39\n",
            "Epoch [299/300] Batch 0/39\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torchvision.utils as vutils\n",
        "import torch\n",
        "\n",
        "# 디바이스 설정 (GPU가 있으면 사용하고, 없으면 CPU 사용)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 300\n",
        "\n",
        "import itertools\n",
        "# 모델 초기화\n",
        "input_nc = 3  # 입력 채널 수 (RGB 이미지이므로 3)\n",
        "output_nc = 3  # 출력 채널 수 (목표 이미지도 RGB이므로 3)\n",
        "\n",
        "G_A2B = ResnetGenerator(input_nc, output_nc).to(device)\n",
        "G_B2A = ResnetGenerator(input_nc, output_nc).to(device)\n",
        "D_A = NLayerDiscriminator(input_nc).to(device)\n",
        "D_B = NLayerDiscriminator(input_nc).to(device)\n",
        "\n",
        "# 옵티마이저 정의\n",
        "optimizer_G = optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# 결과 이미지 저장 폴더 생성 (존재하지 않으면)\n",
        "os.makedirs('/content/drive/MyDrive/Colab Notebooks/resultA', exist_ok=True)\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data_A, data_B) in enumerate(zip(loader_A, loader_B)):\n",
        "        real_A = data_A[0].to(device)\n",
        "        real_B = data_B[0].to(device)\n",
        "\n",
        "        # 제너레이터 업데이트\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        fake_B = G_A2B(real_A)\n",
        "        rec_A = G_B2A(fake_B)\n",
        "\n",
        "        fake_A = G_B2A(real_B)\n",
        "        rec_B = G_A2B(fake_A)\n",
        "\n",
        "        loss_G_A2B = gan_loss(D_B(fake_B), True)\n",
        "        loss_G_B2A = gan_loss(D_A(fake_A), True)\n",
        "\n",
        "        loss_cycle_A = cycle_consistency_loss(real_A, rec_A)\n",
        "        loss_cycle_B = cycle_consistency_loss(real_B, rec_B)\n",
        "\n",
        "        loss_identity_A = identity_loss(real_A, G_B2A(real_A))\n",
        "        loss_identity_B = identity_loss(real_B, G_A2B(real_B))\n",
        "\n",
        "        loss_G = loss_G_A2B + loss_G_B2A + 10 * (loss_cycle_A + loss_cycle_B) + 5 * (loss_identity_A + loss_identity_B)\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # 디스크리미네이터 A 업데이트\n",
        "        optimizer_D_A.zero_grad()\n",
        "        loss_D_A = (gan_loss(D_A(real_A), True) + gan_loss(D_A(fake_A.detach()), False)) * 0.5\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # 디스크리미네이터 B 업데이트\n",
        "        optimizer_D_B.zero_grad()\n",
        "        loss_D_B = (gan_loss(D_B(real_B), True) + gan_loss(D_B(fake_B.detach()), False)) * 0.5\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {i}/{min(len(loader_A), len(loader_B))}\")\n",
        "\n",
        "    # 중간 결과 이미지 저장\n",
        "    if epoch % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            fake_B = G_A2B(real_A)\n",
        "            fake_A = G_B2A(real_B)\n",
        "\n",
        "            # 결과 이미지를 저장 (결과 이미지를 /content/resultA 폴더에 저장)\n",
        "            vutils.save_image(fake_B, f\"/content/drive/MyDrive/Colab Notebooks/resultA/fake_B_epoch_{epoch}.png\", normalize=True)\n",
        "            vutils.save_image(fake_A, f\"/content/drive/MyDrive/Colab Notebooks/resultA/fake_A_epoch_{epoch}.png\", normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후 모델 가중치 저장\n",
        "torch.save(G_A2B.state_dict(), '/content/drive/MyDrive/Colab Notebooks/resultA/G_A2B.pth')\n",
        "torch.save(G_B2A.state_dict(), '/content/drive/MyDrive/Colab Notebooks/resultA/G_B2A.pth')\n",
        "\n",
        "# 모델 초기화\n",
        "G_A2B = ResnetGenerator(input_nc, output_nc).to(device)\n",
        "G_B2A = ResnetGenerator(input_nc, output_nc).to(device)\n",
        "\n",
        "# 저장된 가중치 로드\n",
        "G_A2B.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/resultA/G_A2B.pth'))\n",
        "G_B2A.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/resultA/G_B2A.pth'))\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "G_A2B.eval()\n",
        "G_B2A.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfR9Ji0ZOUrv",
        "outputId": "59fc923c-a2ab-408e-9166-f599ddc823bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResnetGenerator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (10): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (11): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (12): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (13): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (14): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (15): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (16): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (17): ResnetBlock(\n",
              "      (conv_block): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "    (19): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "    (22): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (23): ReLU(inplace=True)\n",
              "    (24): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "    (25): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# 이미지 전처리 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 이미지를 로드하고 전처리\n",
        "img = Image.open('/content/drive/MyDrive/Colab Notebooks/resultA/56721345-b98b-49e9-b7b1-af1c5f243a74.jpg').convert('RGB')\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# 이미지 변환 (한국 동양화를 서양화로 변환하는 예)\n",
        "with torch.no_grad():\n",
        "    output_tensor = G_A2B(img_tensor)\n",
        "\n",
        "# 이미지 후처리\n",
        "output_tensor = output_tensor.squeeze().cpu().detach()\n",
        "output_tensor = (output_tensor + 1) / 2  # [-1, 1] 범위를 [0, 1]로 변환\n",
        "output_img = transforms.ToPILImage()(output_tensor)\n",
        "\n",
        "# 이미지 업스케일링 (예: 512x512)\n",
        "upscale_size = (1920, 1080)  # 원하는 업스케일링 크기\n",
        "output_img = output_img.resize(upscale_size, Image.BICUBIC)\n",
        "\n",
        "# 결과 이미지 저장\n",
        "output_img.save('/content/drive/MyDrive/Colab Notebooks/resultA/output_image_upscaled2.jpg')\n"
      ],
      "metadata": {
        "id": "GXXSUbY3OYEH"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}