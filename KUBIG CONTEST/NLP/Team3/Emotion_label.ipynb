{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMUkT9dR7w26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17d5414-1764-42e7-d5a4-5e326dbc061c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AAGlDMp9HI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XQ4WDGAu-2_i"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# 1. ìµœìƒìœ„ í´ë” ê²½ë¡œ ì„¤ì • (í•˜ìœ„ í´ë”ë“¤ì´ ìˆëŠ” í´ë”)\n",
        "folder_path = '/content/drive/MyDrive/NLP project/á„€á…¡á†·á„Œá…¥á†¼ á„…á…¡á„‡á…¦á†¯á„…á…µá†¼á„ƒá…¦á„‹á…µá„á…¥'\n",
        "\n",
        "# 2. ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì—¬ê¸°ì— ê° íŒŒì¼ì—ì„œ ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ì €ì¥í•  ê²ƒ)\n",
        "all_data = []\n",
        "\n",
        "# 3. os.walk()ë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ìœ„ í´ë”ê¹Œì§€ ëª¨ë“  JSON íŒŒì¼ ì°¾ê¸°\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.json'):  # JSON íŒŒì¼ë§Œ ì²˜ë¦¬\n",
        "            file_path = os.path.join(root, file_name)\n",
        "\n",
        "            # 4. JSON íŒŒì¼ ì½ê¸°\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # 5. í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ (utterancesì—ì„œ listener_empathyê°€ ìˆëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œ)\n",
        "            utterances = data.get('utterances', [])\n",
        "\n",
        "            for utterance in utterances:\n",
        "                if utterance.get('listener_empathy') is not None:\n",
        "                    all_data.append({\n",
        "                        \"text\": utterance['text'],\n",
        "                        \"listener_empathy\": utterance['listener_empathy']\n",
        "                    })\n",
        "\n",
        "# 6. pandas ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "# 7. listener_empathy ë¦¬ìŠ¤íŠ¸ë¥¼ ì½¤ë§ˆë¡œ ì—°ê²°ëœ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "df['emotion_label'] = df['listener_empathy'].apply(lambda x: ', '.join(x))\n",
        "\n",
        "# 8. ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì¶œë ¥ (ë¬¸ì¥ê³¼ ê°ì • ë¼ë²¨)\n",
        "df_final = df[['text', 'emotion_label']]\n",
        "\n",
        "# 9. ë°ì´í„°í”„ë ˆì„ í™•ì¸\n",
        "df_final.head()\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ í¬ê¸° í™•ì¸ (ëª‡ ê°œì˜ ë¬¸ì¥ì´ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€)\n",
        "print(f\"ì´ {len(df_final)}ê°œì˜ ë¬¸ì¥ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "siVTfbrrKAUM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# ë°ì´í„°í”„ë ˆì„ ì €ì¥\n",
        "df_final.to_csv('/content/drive/MyDrive/NLP project/final_dataframe.csv', index=False, encoding='utf-8-sig')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "5jhGYj6HwYxm",
        "outputId": "38bb5bc4-7519-44c2-9eae-e63463b49175"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/emotion_classifier.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-23d808bef00a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/emotion_classifier.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  emotion_classifier csv íŒŒì¼ ë¶ˆëŸ¬ì˜´\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/emotion_classifier.csv'"
          ]
        }
      ],
      "source": [
        "df_final = pd.read_csv('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/emotion_classifier.csv') #  emotion_classifier csv íŒŒì¼ ë¶ˆëŸ¬ì˜´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "syBV8vmfnKhH"
      },
      "outputs": [],
      "source": [
        "df_final.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "QWX5xAyvnMAP",
        "outputId": "470ee615-40c4-4937-ce97-f9e297430c9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°</th>\n",
              "      <td>24513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ìœ„ë¡œ, ë™ì¡°</th>\n",
              "      <td>18339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤</th>\n",
              "      <td>17702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ìœ„ë¡œ</th>\n",
              "      <td>16320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ë™ì¡°</th>\n",
              "      <td>14975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸</th>\n",
              "      <td>12956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ê²©ë ¤</th>\n",
              "      <td>10120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ë™ì¡°</th>\n",
              "      <td>9152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ìœ„ë¡œ</th>\n",
              "      <td>8002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ìœ„ë¡œ</th>\n",
              "      <td>4037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ê²©ë ¤, ë™ì¡°</th>\n",
              "      <td>2526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ìœ„ë¡œ, ë™ì¡°</th>\n",
              "      <td>2504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ê²©ë ¤, ìœ„ë¡œ</th>\n",
              "      <td>1923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ìœ„ë¡œ, ë™ì¡°</th>\n",
              "      <td>1570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ê²©ë ¤</th>\n",
              "      <td>502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ì¡°ì–¸</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ì¡°ì–¸</th>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ìœ„ë¡œ</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ì¡°ì–¸, ê²©ë ¤, ìœ„ë¡œ, ë™ì¡°</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ê²©ë ¤, ìœ„ë¡œ</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ë™ì¡°, ìœ„ë¡œ</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ì¡°ì–¸, ìœ„ë¡œ</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ë™ì¡°, ê²©ë ¤, ì¡°ì–¸</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ë™ì¡°, ì¡°ì–¸</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ê²©ë ¤, ì¡°ì–¸, ìœ„ë¡œ</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "emotion_label\n",
              "ë™ì¡°                24513\n",
              "ìœ„ë¡œ, ë™ì¡°            18339\n",
              "ê²©ë ¤                17702\n",
              "ìœ„ë¡œ                16320\n",
              "ê²©ë ¤, ë™ì¡°            14975\n",
              "ì¡°ì–¸                12956\n",
              "ì¡°ì–¸, ê²©ë ¤            10120\n",
              "ì¡°ì–¸, ë™ì¡°             9152\n",
              "ì¡°ì–¸, ìœ„ë¡œ             8002\n",
              "ê²©ë ¤, ìœ„ë¡œ             4037\n",
              "ì¡°ì–¸, ê²©ë ¤, ë™ì¡°         2526\n",
              "ì¡°ì–¸, ìœ„ë¡œ, ë™ì¡°         2504\n",
              "ì¡°ì–¸, ê²©ë ¤, ìœ„ë¡œ         1923\n",
              "ê²©ë ¤, ìœ„ë¡œ, ë™ì¡°         1570\n",
              "ë™ì¡°, ê²©ë ¤              502\n",
              "ê²©ë ¤, ì¡°ì–¸               77\n",
              "ë™ì¡°, ì¡°ì–¸               69\n",
              "ë™ì¡°, ìœ„ë¡œ               61\n",
              "ì¡°ì–¸, ê²©ë ¤, ìœ„ë¡œ, ë™ì¡°       18\n",
              "ë™ì¡°, ê²©ë ¤, ìœ„ë¡œ           11\n",
              "ê²©ë ¤, ë™ì¡°, ìœ„ë¡œ            7\n",
              "ë™ì¡°, ì¡°ì–¸, ìœ„ë¡œ            6\n",
              "ë™ì¡°, ê²©ë ¤, ì¡°ì–¸            5\n",
              "ê²©ë ¤, ë™ì¡°, ì¡°ì–¸            5\n",
              "ê²©ë ¤, ì¡°ì–¸, ìœ„ë¡œ            4\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.value_counts('emotion_label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9KkHeRmKitR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSzvKiuXMSOD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ê°€ëŠ¥í•œ ëª¨ë“  ê°ì • ë ˆì´ë¸” ì •ì˜\n",
        "possible_labels = [\"ê²©ë ¤\", \"ë™ì¡°\", \"ìœ„ë¡œ\", \"ì¡°ì–¸\"]\n",
        "\n",
        "#  ë¼ë²¨ì„ ë‹¤ì¤‘ ë¼ë²¨ ë²¡í„°ë¡œ ë³€í™˜\n",
        "# ì˜ˆ: [\"ê²©ë ¤\", \"ìœ„ë¡œ\"] -> [1, 0, 1, 0] (ê²©ë ¤ì™€ ìœ„ë¡œëŠ” í•´ë‹¹, ë™ì¡°ì™€ ì¡°ì–¸ì€ í•´ë‹¹í•˜ì§€ ì•ŠìŒ)\n",
        "def encode_labels(labels, possible_labels):\n",
        "    label_vector = [1 if label in labels else 0 for label in possible_labels]\n",
        "    return label_vector\n",
        "\n",
        "df_final['encoded_label'] = df_final['emotion_label'].apply(lambda x: encode_labels(x, possible_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vq_tgqwMj17"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df_final['text'], df_final['encoded_label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHCDK0XizjBl"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# ALBERT í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ\n",
        "\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJOMUZipz4Xd"
      },
      "outputs": [],
      "source": [
        "''''\n",
        "\n",
        "# Roberta í† í¬ë‚˜ì´ì € ëª¨ë¸ ë° ë¡œë“œ\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtqnP_PiMlzS",
        "outputId": "018a49a2-3223-4842-9550-4bab7ef458d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#  BERT í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(possible_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i4WY1ZTl9eL",
        "outputId": "597ba061-262f-4940-808c-46d0c6647eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 6. CUDA ì‚¬ìš© ì—¬ë¶€ í™•ì¸ ë° ëª¨ë¸ ì´ë™\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)  # ëª¨ë¸ì„ GPUë¡œ ì´ë™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZidSCa8cnhaI",
        "outputId": "8ba56773-8be0-48bd-c4c0-f663798710c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWuMA7KvMnol"
      },
      "outputs": [],
      "source": [
        "#  ë°ì´í„°ì…‹ ì¤€ë¹„\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=64, return_tensors=\"pt\")\n",
        "        self.labels = torch.tensor(labels.tolist(), dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-3nSk2TMo_E"
      },
      "outputs": [],
      "source": [
        "train_dataset = MultiLabelDataset(train_texts, train_labels)\n",
        "val_dataset = MultiLabelDataset(val_texts, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkj7Uew3Mqm3",
        "outputId": "64fc6348-13ec-431a-c7ee-2c2d71192297"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#  í•™ìŠµ ì„¤ì •\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/results',\n",
        "    num_train_epochs=3,\n",
        "    save_steps=2_000,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/logs',\n",
        "    logging_steps=1000,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3XTkWCQMtKV"
      },
      "outputs": [],
      "source": [
        "#  Trainer ì„¤ì •\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "qE3RfZmQMvC6",
        "outputId": "3541f42a-b90a-43ea-fe66-0f87fb4a6786"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10908' max='10908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10908/10908 1:10:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.554500</td>\n",
              "      <td>0.528382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.506600</td>\n",
              "      <td>0.502544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.479300</td>\n",
              "      <td>0.494819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10908, training_loss=0.5246419875141811, metrics={'train_runtime': 4243.4472, 'train_samples_per_second': 82.237, 'train_steps_per_second': 2.571, 'total_flos': 1.1477406333040128e+16, 'train_loss': 0.5246419875141811, 'epoch': 3.0})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  ëª¨ë¸ í•™ìŠµ\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "NHBrLwLMNReb",
        "outputId": "3268622e-50aa-4c66-cf7c-567c5f3c822f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='909' max='909' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [909/909 01:43]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4948192238807678,\n",
              " 'eval_runtime': 103.3002,\n",
              " 'eval_samples_per_second': 281.519,\n",
              " 'eval_steps_per_second': 8.8,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  ëª¨ë¸ í‰ê°€\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84GBYuE6pL79"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥ (ê²½ë¡œ ë”°ë¡œ ì„¤ì • í•„ìš”)\n",
        "model.save_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')\n",
        "\n",
        "# ì €ì¥ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸° (ê²½ë¡œ ë”°ë¡œ ì„¤ì • í•„ìš”)\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Bx-o8chdhejD",
        "outputId": "e7406f01-0023-4eaf-ca8a-64e2cb247ea3"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "Incorrect path_or_model_id: '/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a3fcc1ba53cb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ì €ì¥ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸° (ê²½ë¡œ ë”°ë¡œ ì„¤ì • í•„ìš”)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3127\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3128\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   3129\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3130\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         ) from e\n",
            "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# ì €ì¥ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸° (ê²½ë¡œ ë”°ë¡œ ì„¤ì • í•„ìš”)\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/KUBIG CONTEST NLP-Team3/19_á„á…¬á„Œá…µá„‹á…®/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaM7CV0CokgA"
      },
      "outputs": [],
      "source": [
        "def predict_empathy_label(model, tokenizer, text, possible_labels, device='cpu'):\n",
        "    \"\"\"\n",
        "    ì…ë ¥ëœ ë¬¸ì¥ì— ëŒ€í•œ ê³µê° ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Args:\n",
        "        model: í•™ìŠµëœ BERT ëª¨ë¸ (BertForSequenceClassification)\n",
        "        tokenizer: BERT í† í¬ë‚˜ì´ì € (BertTokenizer)\n",
        "        text: ì˜ˆì¸¡í•  ë¬¸ì¥ (str)\n",
        "        possible_labels: ê°€ëŠ¥í•œ ëª¨ë“  ê³µê° ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ê²©ë ¤\", \"ë™ì¡°\", \"ìœ„ë¡œ\", \"ì¡°ì–¸\"])\n",
        "        device: ì‚¬ìš©í•  ì¥ì¹˜ (GPU ë˜ëŠ” CPU)\n",
        "\n",
        "    Returns:\n",
        "        predicted_emotions: ì˜ˆì¸¡ëœ ê³µê° ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ê²©ë ¤\", \"ìœ„ë¡œ\"])\n",
        "    \"\"\"\n",
        "\n",
        "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.eval()\n",
        "\n",
        "    # ì…ë ¥ ë¬¸ì¥ì„ BERT ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™\n",
        "    inputs = tokenizer(text, truncation=True, padding=True, max_length=64, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # ì‹œê·¸ëª¨ì´ë“œë¥¼ í†µí•´ ê° ê°ì •ì— ëŒ€í•œ í™•ë¥ ë¡œ ë³€í™˜\n",
        "    predictions = torch.sigmoid(logits)\n",
        "\n",
        "    # ì„ê³„ê°’(threshold)ì„ ì„¤ì •í•´ í•´ë‹¹ ê°ì •ì— ì†í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì • (0.5 ì´ìƒì¼ ê²½ìš° ê°ì •ì´ í•´ë‹¹í•œë‹¤ê³  íŒë‹¨)\n",
        "    threshold = 0.5\n",
        "    predicted_labels = (predictions > threshold).int().tolist()[0]\n",
        "\n",
        "    # ì˜ˆì¸¡ëœ ë¼ë²¨ì„ ì‹¤ì œ ê°ì •ìœ¼ë¡œ ë³€í™˜\n",
        "    predicted_emotions = [possible_labels[i] for i, label in enumerate(predicted_labels) if label == 1]\n",
        "    print(predictions)\n",
        "    return predicted_emotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRpSZ6oDouy0",
        "outputId": "137ffffe-44c1-470c-f729-cc43a4a7aa2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2547, 0.5680, 0.0708, 0.3061]], device='cuda:0')\n",
            "ì˜ˆì¸¡ëœ ê³µê° ë¼ë²¨: ['ë™ì¡°', 'ì¡°ì–¸']\n"
          ]
        }
      ],
      "source": [
        "# ê°€ëŠ¥í•œ ê³µê° ë¼ë²¨ ì •ì˜ (ì´ ì˜ˆì‹œì—ì„œëŠ” [\"ê²©ë ¤\", \"ë™ì¡°\", \"ìœ„ë¡œ\", \"ì¡°ì–¸\"])\n",
        "possible_labels = [\"ê²©ë ¤\", \"ë™ì¡°\", \"ìœ„ë¡œ\", \"ì¡°ì–¸\"]\n",
        "\n",
        "# ì˜ˆì‹œ ë¬¸ì¥\n",
        "new_sentence = \"ìœ„ë¡œê°€ ë‚˜ì˜¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ì§€?\"\n",
        "\n",
        "# ì˜ˆì¸¡ í•¨ìˆ˜ í˜¸ì¶œ (í•™ìŠµëœ ëª¨ë¸, í† í¬ë‚˜ì´ì €, ì˜ˆì¸¡í•  ë¬¸ì¥, ê°€ëŠ¥í•œ ê³µê° ë¼ë²¨, GPU ì¥ì¹˜)\n",
        "predicted_empathy = predict_empathy_label(model, tokenizer, new_sentence, possible_labels, device)\n",
        "\n",
        "print(f\"ì˜ˆì¸¡ëœ ê³µê° ë¼ë²¨: {predicted_empathy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}